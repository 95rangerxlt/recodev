Bug 380194 introduced same changes to the parser / scanner that affect performance. The design works hard to avoid performance degradation but so far we have no measurements that can guide us in the choice between different strategies.

E.g., I'd like to see if method Parser.parserAtConflictScenario() is worth the effort: is it saving relevant efforts in scanner look-ahead (Scanner.atLambdaParameterList() and atReferenceExpression()) to balance the initial efforts?

In a first naive measurement I ran org.eclipse.jdt.core.tests.compiler.parser.TestAll with slight variations in the code.

To my own surprise I saw that simply turning 1.8 mode on seemed to degrade performance by approx. 9%, but I could not observe any difference related to parserAtConflictScenario() (delta < 0.1%).

At this point the experiment was too naive to yield reliable figures but there seems to be some issue that I'd like to narrow down before finalizing the new parser design.

Can we identify a relevant subset of tests? Is ...parser.TestAll already a good candidate?

What would be a test case for the worst case scenarios mentioned in bug 380194 comment 24?

Bug 380194 introduced same changes to the parser / scanner that affect performance. The design works hard to avoid performance degradation but so far we have no measurements that can guide us in the choice between different strategies.

E.g., I'd like to see if method Parser.parserAtConflictScenario() is worth the effort: is it saving relevant efforts in scanner look-ahead (Scanner.atLambdaParameterList() and atReferenceExpression()) to balance the initial efforts?

In a first naive measurement I ran org.eclipse.jdt.core.tests.compiler.parser.TestAll with slight variations in the code.

To my own surprise I saw that simply turning 1.8 mode on seemed to degrade performance by approx. 9%, but I could not observe any difference related to parserAtConflictScenario() (delta < 0.1%).

At this point the experiment was too naive to yield reliable figures but there seems to be some issue that I'd like to narrow down before finalizing the new parser design.

Can we identify a relevant subset of tests? Is ...parser.TestAll already a good candidate?

What would be a test case for the worst case scenarios mentioned in bug 380194 comment 24?
(In reply to comment #0)

> In a first naive measurement I ran
> org.eclipse.jdt.core.tests.compiler.parser.TestAll with slight variations in
> the code.

Could you document these variations here via a patch ? TIA.

> To my own surprise I saw that simply turning 1.8 mode on seemed to degrade
> performance by approx. 9%, but I could not observe any difference related to
> parserAtConflictScenario() (delta < 0.1%).

Could you also post the actual numbers, not just %ages ? Also what did you
mean by "I could not observe ..."

Did you also the get the numbers by short-circuiting the call to parserAtConflictScenario (so it always answers true) and that didn't help ? 
Is that what you mean by  "I could not observe ..." ?

> Can we identify a relevant subset of tests? Is ...parser.TestAll already a good
> candidate?

It is a good candidate as is, though let us not use it as the only candidate.
I would also include a full build of Eclipse SDK with a specially concocted version that looks ahead at all source levels.

> What would be a test case for the worst case scenarios mentioned in bug 380194
> comment 24?

Originally a worst case scenario would have been a large method that has
several checks of the form if (x < y) {}, with no code of form if (x > y))
but due the introduction of black list, the worst case scenario is mitigated
already and the look ahead should fail "reasonably early". So perhaps we
don't have to devise a special test case for this.
(In reply to comment #0)

> To my own surprise I saw that simply turning 1.8 mode on seemed to degrade
> performance by approx. 9%, but I could not observe any difference related to
> parserAtConflictScenario() (delta < 0.1%).

I think we can recover nearly all of this performance drop for the "common
scenarios" by -

    - No look ahead at all for source level 1.7- (as it is now)
    - At source level 1.8, NO look ahead "normally", NOR will the
      parser try to investigate whether it is at a potential conflict 
      site and demand disambiguation.
    - When the parser encounters the first syntax error at source level 
      1.8+, it starts over a la mode RESTART_IN_WIDE_MODE.

The reconciler scenario is very important too and that will trigger the
restart mode fairly frequently - so we need to fine tune this a bit more.
As a first cut, we can arrange for a restart to happen only if either of
the tokens -> or :: are seen in the file. I am not sure if there are cases
where we would give up soon enough to not notice the ->/:: tokens - hence
my mentioning "the first syntax error".

> What would be a test case for the worst case scenarios mentioned in bug 380194
> comment 24?

Any test case where the "distance" between '<' and one of { '{' '}', ';' '>' }
would be "high". As already mentioned, the use of black list already addresses the worst case which is to scan until EOF.
(In reply to comment #1)
> (In reply to comment #0)
> 
> > In a first naive measurement I ran
> > org.eclipse.jdt.core.tests.compiler.parser.TestAll with slight variations in
> > the code.
> 
> Could you document these variations here via a patch ? TIA.

Nothing magic here, just
(a) forcing Parser.parsingJava8Plus and Scanner.scanningJava8Plus to true
(b) replacing "parserAtConflictScenario(lastAction, token)" with "true"

 
> > To my own surprise I saw that simply turning 1.8 mode on seemed to degrade
> > performance by approx. 9%,

this was achieved by (a) above.

> > but I could not observe any difference related to
> > parserAtConflictScenario() (delta < 0.1%).

this being the difference caused by  (b)
 
> Could you also post the actual numbers, not just %ages ?

No valuable data beyond what I extracted. One typical test run was approx. 40sec. in the good case,
43 sec. in the slower variant (1.8).

All I'm saying is: naive experiments show we need real experiments.

I'd like to learn, where exactly those "9%" are spent (to be replaced with a better supported figure - maybe a real experiment proves this to be a red herring).

> Also what did you mean by "I could not observe ..."

I observed a non-significant difference of less than 0.1%.

> Did you also the get the numbers by short-circuiting the call to
> parserAtConflictScenario (so it always answers true) and that didn't help ?
> Is that what you mean by  "I could not observe ..." ?

Exactly, it neither helped nor hurt.

> > Can we identify a relevant subset of tests? Is ...parser.TestAll already a
> good
> > candidate?
> 
> It is a good candidate as is, though let us not use it as the only candidate.
> I would also include a full build of Eclipse SDK with a specially concocted
> version that looks ahead at all source levels.

Here it would perhaps help to also short-circuit all later compiler phase, so we concentrate on measuring the parser, right?
 
> > What would be a test case for the worst case scenarios mentioned in bug 380194
> > comment 24?
> 
> Originally a worst case scenario would have been a large method that has
> several checks of the form if (x < y) {}, with no code of form if (x > y))
> but due the introduction of black list, the worst case scenario is mitigated
> already and the look ahead should fail "reasonably early". So perhaps we
> don't have to devise a special test case for this.

I'm just challenging the necessity of parserAtConflictScenario(). If we can't demonstrate that it is needed for performance, I would suggest to remove it (which would make me more comfortable, because I don't yet understand how exactly that method works :) ).
If you have a worst case test case this could give a hint about a potential benefit.
(In reply to comment #3)
 
> Here it would perhaps help to also short-circuit all later compiler phase, so
> we concentrate on measuring the parser, right?

I would say yes if there are material changes to downstream phases that could
overwhelm or otherwise shift the hot spots, but at the moment, there aren't any
material downstream changes to skew/alter/distort the scenario. So measuring
the overall degradation is better. 

> I'm just challenging the necessity of parserAtConflictScenario(). If we can't
> demonstrate that it is needed for performance, I would suggest to remove it

That would be fine.

> (which would make me more comfortable, because I don't yet understand how
> exactly that method works :) ).

:) 

It is the same automaton we have gotten accustomed to and have grown to love 
in Parse.parse(), but is a "rotated" version of it: So some code from its
tail sits on top of its head. 

Basically it checks if the parser at the configuration it is in, will ever 
shift the synthetic symbol TokenNameBeginLambda. Since it is an axiom that
the LALR parser (may reduce, but) will never shift on bad input, it indicates
whether we are at a point in the parse where a lambda expression may be seen
==> '(' needs disambiguation (same argument for '<')

Rather than remove, I'll leave the code in as is, not use it and point a
comment to here, if the data shows it is not buying much or worsens.
I would however implement a precomputed cache for tAction(lastAction, token)
lookup as the comment calls out there - FWIW.

It was just abhorrent to me to implement look ahead unconditionally, but 
in real terms I agree this could simply be switching the nature of work :)

> If you have a worst case test case this could give a hint about a potential
> benefit.

No, other than the already mitigated "'<' operator and not open type arguments 
with  '<'" case, I can't think of any.
(In reply to comment #4)
> (In reply to comment #3)

> Rather than remove, I'll leave the code in as is, not use it and point a
> comment to here, if the data shows it is not buying much or worsens.
> I would however implement a precomputed cache for tAction(lastAction, token)
> lookup as the comment calls out there - FWIW.

That doesn't read right - the cache recommendation is for the measurement.
"Leave it in, don't use" recommendation is if the measurement shows the conflict
scenario check is not helping (and not for the cache).

BTW, in https://bugs.eclipse.org/bugs/show_bug.cgi?id=287648, I am
preparing for a big checkin this week - do you think I should hold it
till we resolve this issue or we can workaround easily to eliminate
these latter unconnected changes using some version control magic ?
(In reply to comment #2)
> (In reply to comment #0)
> 
> > To my own surprise I saw that simply turning 1.8 mode on seemed to degrade
> > performance by approx. 9%, but I could not observe any difference related to
> > parserAtConflictScenario() (delta < 0.1%).
> 
> I think we can recover nearly all of this performance drop for the "common
> scenarios" by -

Here is some more ways to improve performance: If we extend the LR parser's
FIRST and FOLLOW set terminology with a PRECEDES set that contains the set 
of tokens that could precede a non terminal, then

PRECEDES(Lambda) = { "=", "return", "(", (")", ",", "->" }

where "=", "return", "->" signal assignment context,
"(" from invocation context or parenthesized expression context,
")" from casting context and
"," from invocation context

So the scanner has to look ahead on a "(" only if it was preceded by
one of these tokens.  

The case of lookahead on "<" lend itself well to a similar strategy 
though.

Alternately, we could precompute some data that would allow us to
do the following from 4.7.1 Canonical LR(1) items, Compilers, techniques
and tools: Aho, Lam, Sethi, Ulman, page 260:

"By splitting states when necessary, we can arrange to have each state
of an LR parser indicate exactly which input symbols can follow a handle
α for which there is a possible reduction to A."

The only lookahead tokens of interest are BeginLambda and BeginTypeArguments
so the tables will not be memory intensive: given any state of the parser
one lookup from an array would answer if we are at a conflict site.
(In reply to comment #6)

> The case of lookahead on "<" lend itself well to a similar strategy 
> though.

should read: DOES NOT lend itself well.
(In reply to comment #6)

> PRECEDES(Lambda) = { "=", "return", "(", (")", ",", "->" }

Fixing a typo and adding the tokens from the ternary operator, this 
should read:

  PRECEDES(Lambda) = { "=", "return", "(", ")", ",", "->", "?", ":" }
(In reply to comment #8)

>   PRECEDES(Lambda) = { "=", "return", "(", ")", ",", "->", "?", ":" }

Stephan, does this set look right and exhaustive ? If so, 

(In reply to comment #7)
> (In reply to comment #6)
> 
> > The case of lookahead on "<" lend itself well to a similar strategy 
> > though.
> 
> should read: DOES NOT lend itself well.

This may not be an issue after all. We should be able to build a straight
forward and cheap state machine all in the scanner with no help from the 
parser  that indicates whether look ahead is called for not.

STATE# 0 = START STATE:

    LA('(') = false, LA('<') = false
    ∀ t ∈ { "=", "return", "(", ")", ",", "->", "?", ":" } goto STATE# 1

STATE# 1:

    LA('(') = true, LA('<') = false
    On Identifier goto STATE# 2
    ∀ t ∉ { "=", "return", "(", ")", ",", "->", "?", ":" } goto STATE# 0

STATE# 2

    LA('(') = false, LA('<') = true
    On '.' goto STATE# 3
    ∀ t ∉ { "=", "return", "(", ")", ",", "->", "?", ":" } goto STATE# 0
    ∀ t ∈ { "=", "return", "(", ")", ",", "->", "?", ":" } goto STATE# 1

STATE# 3

    LA('(') = false, LA('<') = false
    On Identifier goto STATE# 2
    ∀ t ∉ { "=", "return", "(", ")", ",", "->", "?", ":" } goto STATE# 0
    ∀ t ∈ { "=", "return", "(", ")", ",", "->", "?", ":" } goto STATE# 1
(In reply to comment #1)

> > What would be a test case for the worst case scenarios mentioned in bug 380194
> > comment 24?
> 
> Originally a worst case scenario would have been a large method that has
> several checks of the form if (x < y) {}, with no code of form if (x > y))
> but due the introduction of black list, the worst case scenario is mitigated
> already and the look ahead should fail "reasonably early". So perhaps we
> don't have to devise a special test case for this.

[Posted on the other bug my mistake, updating current topic also for
posterity]

That is altogether overlooking the all too common scenario of parenthesis
imbalance: What happens if in a large otherwise syntactically valid file, 
early on there is a missing ')' ? We would scan all the way to EOF (assuming 
diet parsing is not in effect.) Of course, the imbalance could be at the
conflict scenario too :) We may need to build black lists for () also or
come up with other means of failing early.

I am devising some measurements, stay tuned.
OK, here is some very interesting data:

Experiment:

Launch Juno on an empty workspace, import all plugins from platform as source
projects. Disable automatic build after clean. See that a bunch of projects
have a build errors, while others build cleanly, we don't care about this.

Using Juno:

    for (i = 0; i < 3; i++) {
       Clean workspace,
       Quit & Relaunch
       Build all project and measure elapsed time
    }
    Average = 223 seconds

On a BETA_JAVA8 workspace reset to 7ae9e904164ab9e611ba46366de94e1b02c0e7e7:

    Average = 228 seconds.

On a BETA_JAVA8 workspace reset to c0fbf538c56e049473d6298631299cfef92195c1:

    Average = 230 seconds.

On a BETA_JAVA8 workspace reset to c0fbf538c56e049473d6298631299cfef92195c1:
+ ScanningJava8Plus and ParsingJava8 forced to be true:

    Average = 232 seconds.

On a BETA_JAVA8 workspace reset to c0fbf538c56e049473d6298631299cfef92195c1:
+ ScanningJava8Plus and ParsingJava8 + parserAtConflictScenario forced to be
true:

    Average = 232 seconds.

Now, in summary the forced/always look ahead may not in and off itself be
performance issue for welformed programs. For malformed programs with
imbalanced parenthesis etc, we should still determine the worst case
complexity since look ahead at the moment will be until EOF. And find
ways to ameliorate it.

Bottomline: Is parserAtConflictScenario worth it ? NO seems to be the
clear answer for well formed programs.

I'll recreate Stephan's experiments with TestAll shortly.
(In reply to comment #3)

> > > To my own surprise I saw that simply turning 1.8 mode on seemed to degrade
> > > performance by approx. 9%,

Didn't ask earlier: What was the source of surprise ? You expected more or
less ? :)

> I'd like to learn, where exactly those "9%" are spent (to be replaced with a
> better supported figure - maybe a real experiment proves this to be a red
> herring).

As SOP, we should average over multiple runs before determining delta. 
Also if we are not shutting down and restarting between benchmarks, we 
should discard the first number - Not sure if this was done already.

> Here it would perhaps help to also short-circuit all later compiler phase, so
> we concentrate on measuring the parser, right?

Thinking a bit more about it, I don't think we short circuit anything. What do
we care if there is a 100% degradation in some component X if X contributes
say only to 1% of overall execution time ? Since the overall elapsed time is 
what the users perceive, that should be the focus.

I second your suggestion that we should profile and understand the delta
between Juno and the snapshots referred to in earlier comments.
Average across multiple runs, I don't see a statistically significant
difference between the numbers for running TestAll with:

    - On a BETA_JAVA8 workspace reset to 
      c0fbf538c56e049473d6298631299cfef92195c1:

    - On a BETA_JAVA8 workspace reset to 
      c0fbf538c56e049473d6298631299cfef92195c1:
      + ScanningJava8Plus and ParsingJava8 forced to be true:

    - On a BETA_JAVA8 workspace reset to 
      c0fbf538c56e049473d6298631299cfef92195c1:
      + ScanningJava8Plus and ParsingJava8 + parserAtConflictScenario 
      forced to be true

They all take about 59 seconds on my machine.

Stephan, when you get the time you may want to recreate the Juno plugins 
as source projects experiment and we can compare notes and chalk out a
POA.
(In reply to comment #12)

> As SOP, we should average over multiple runs before determining delta. 
> Also if we are not shutting down and restarting between benchmarks, we 
> should discard the first number - Not sure if this was done already.

Actually I see that this is perhaps answered already indirectly in
comment#0 and comment# 3.
If any performance tuning is determined to be necessary in the look ahead
strategy, plausibly to attenuate the worst case scenario, then any fixes
should also take into account the DiagnoseParser. 

At the moment the diagnose parser always runs the scanner in a "proactively 
look ahead and disambiguate uses of '<' and '(' at 1.8+ modes" mode. 

There is too much voodoo going on in DiagnoseParser (3 automatons running 
concurrently marching in lock step, one behind the other, a buffered token
stream that could be scanned over and over as different recovery strategies
are tried out etc) that it is a bit challenging to implement the kind of
tight coupling that is called for in the solution adopted for the general
parser. See bug# 383046
(In reply to comment #11)

> Using Juno:

> On a BETA_JAVA8 workspace reset to 7ae9e904164ab9e611ba46366de94e1b02c0e7e7:

> On a BETA_JAVA8 workspace reset to c0fbf538c56e049473d6298631299cfef92195c1:

> On a BETA_JAVA8 workspace reset to c0fbf538c56e049473d6298631299cfef92195c1:

> On a BETA_JAVA8 workspace reset to c0fbf538c56e049473d6298631299cfef92195c1:

I'll repost these results as what is documented in comment#11 is not a
well controlled experiment. The JVM used for running Juno (JRE6) was different
from all the other ones (JRE7)
(In reply to comment #9)
> (In reply to comment #8)

> STATE# 0 = START STATE:
> 
>     LA('(') = false, LA('<') = false
>     ∀ t ∈ { "=", "return", "(", ")", ",", "->", "?", ":" } goto STATE# 1
> 
> STATE# 1:
> 
>     LA('(') = true, LA('<') = false
>     On Identifier goto STATE# 2
>     ∀ t ∉ { "=", "return", "(", ")", ",", "->", "?", ":" } goto STATE# 0
> 
> STATE# 2
> 
>     LA('(') = false, LA('<') = true
>     On '.' goto STATE# 3
>     ∀ t ∉ { "=", "return", "(", ")", ",", "->", "?", ":" } goto STATE# 0
>     ∀ t ∈ { "=", "return", "(", ")", ",", "->", "?", ":" } goto STATE# 1

Of course JSR308 has to come in and mess up my nice state machine with
annotations on nested names :-(

So a reference expression could start with

X. @Blah(value = "Complex") Y<String>::

It can be reworked to be a bit approximate but conservative.
Created attachment 218706
Patch under test

Has seen only minimal test, but this captures the basic idea
for a simple & cheap state machine that serves as an oracle to
answer the question whether the scanner should look ahead to
disambiguate.

    - This patch gets rid of the parserAtConflictScenario() method and
in fact all involvement from the parser.
    - Simplifies the scanner quite a bit.

Under test.
(In reply to comment #18)
> Created attachment 218706 [details]
> Patch under test

This should automatically fix:

https://bugs.eclipse.org/bugs/show_bug.cgi?id=381358 and some cases
of https://bugs.eclipse.org/bugs/show_bug.cgi?id=382702

(the former since look ahead is now implemented for all modes under the
premise that is is very cheap - still needs final validation by benchmarks.)
(In reply to comment #19)

> Under test.

Passes all tests. Stephan, could you review this one too ? This should be
the last of the review requests in this round at least for quite a few 
weeks.
(In reply to comment #18)
> Created attachment 218706 [details]
> Patch under test

Basically we will now implement look ahead at all source levels, but on a '('
we will never look ahead in:

    - if (), while (), for (), catch(), switch() do while(), 
      synchronized(), try() ...
    - Method/constructor headers & invocations including this and 
      super calls, annotation arguments ...

For '<' we will look ahead at every instance of it following an identifier.
As mentioned in comment#17, JSR308 annotations make it impossible for a DFA
to be constructed to serve as an oracle (since counting is required to know
when annotation tokens end and a DFA cannot count)
(In reply to comment #18)

> Under test.

Released in BETA_JAVA8 via http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=4c2900096a422605a0884d5ca39839064ce0c89a.

After quite a bit of agonizing and vacillating, I restored the older
behavior that look ahead will happen only at source levels 1.8+. Even
though experiments show the cost of look ahead is minimal, it sounds
totally lame to be doing at 1.7- in the hope of being able to report
better messages. Even at 1.8+, the hit/miss ratio is going to be quite
low, but in this case, it is the inherent cost of doing business. For
1.7-, improving quality of messages is a separate topic covered by
bug 381358.

After controlling for identical VM, I don't see any mentionworthy
variance/degradation in TestAll case and in the SDK build case. It
was frustrating though that there were fairly wide swings in the numbers
(both in base line and candidate being calibrated) though averages 
tally up.

Some points for future benchmarking exercises:

    - Always do a clean reboot before starting benchmarking.
    - Control for battery vs wall outlet: It has to be wall uniformly.
    - Laptop has to be on terra firma, not literally in your lap top.
  
Finally, it was amusing to note that, clean sometimes takes more time 
than to rebuild all. The intrinsic work content in building Java 
projects is obviously less than scrubbing harddisk :)

I am all set to close this after review, being convinced that the 
extra work we do is quintessential/intrinsic to the current design and
any short cut would sacrifice rigor - If there are some cheap ways to 
minimize look ahead at '<' that I have overlooked, I would still like 
to look at them despite the numbers not screaming for attention there.
(In reply to comment #22)
> (In reply to comment #18)
> 
> > Under test.
> 
> Released in BETA_JAVA8 via
> http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=4c2900096a422605a0884d5ca39839064ce0c89a.

Again the scanner changes are easier/better reviewed in one shot
by comparing them to master rather than to BETA_JAVA8.
Created attachment 218724
Follow up patch under test

After yet much more agonizing and vacillating, I have decided to reinstate
the look ahead policy management via Parser.atConflictScenario(). I would
have been happy to settle for a cheap DFA based approach, but as mentioned
earlier, 308 ruins the possibility of it and forces us to settle for gross
approximations - We don't have heavily generified code to test and the prospect
of having to look ahead at every '<' that follows an identifier worries me.

At the moment, there is no indication that this method is hurting and given 
that, I'll settle for the rigor it provides any day over hacks (the DFA based
approached would not have been a hack IMO, but for the 308 complications) or
uncertainties.

Upon some sole searching, I realize that my repeated uses of the word 
canonical, standard, orthodox etc in https://bugs.eclipse.org/bugs/show_bug.cgi?id=380194 are perhaps due to the concern in the back of my mind that the 
original implementation could stand a bit more rigor - something the 
combination of the VanguardParser and atConflictScenario affords us.
At that point the ultra-urgent order of business was to rule out the worst 
case scenario of junking the parser infrastructure altogether and so putting
together something quick & not particularly dirty was the right thing to do.
But now that that cloud seems to have passed, we should take a critical look
to strengthen the design & implementation and the present patch is in the 
right direction.

FWIW, the reinstatement leaves the scanner code cleaner that what it was before
atConflictScenario was ripped out in the first place.

Stephan,

My tests indicate there is no performance concern to go after, 
let me know if your experiments indicate otherwise - if they do, I am
willing to leave the present bug OPEN and revisit it later - At the
moment the priority is to make progress on the semantic analysis and
type resolution/inference projects.

That leaves us with your original concern around understandability of
this method - I am willing to help with that. Why don't you study it
and then we can discuss any parts that need to be clarified ? Complexity
wise this piece of code is orders of magnitude simpler than the voodoo
that happens in DiagnoseParser and IMO, it it not needless complexity
we are signing up for.

With this patch in place, the body of work we have so far looks pretty
good and I expect to sleep better !

The only piece that still needs firming up is (as you called out) the 
AST abstraction for ReferenceExpression. It is clunky at the moment, I'll 
get to it soon.
All tests pass. Released in JAVA8 via http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=e0956e75ff6cb3066016adc9dae90f9c1534dda4.

Note: the last round of measurements which didn't show any degradations
other than some run to run variations, were actually carried out with
BETA_JAVA8 top of trunk + the candidate patches i.e they included JSR 308
related changes too.
(In reply to comment #25)

> Note: the last round of measurements which didn't show any degradations
> other than some run to run variations, were actually carried out with
> BETA_JAVA8 top of trunk + the candidate patches i.e they included JSR 308
> related changes too.

Here are the up to date numbers:

Notes:

    - All measurements while running on battery.
    - Each number below is the average over 3 runs rounded up individually
      and again after averaging.
    - Benchmark : org.eclipse.jdt.core.tests.compiler.parser.TestAll
    - Timing : As reported by junit runner.

(1) Reset to commit id 972c7f1c4d5a8249e6cf0bbf33078118344b368a which predates
ANY grammar change in BETA_JAVA8 branch:

    140 seconds

(2) Reset to commit id fa76c3ec72ce5ca3743ba534e916cc81952bcc4a which is NOW:

    141 seconds.

(3) Same commit as (2) + scanningJava8Plus force initialized to true (Note:
parsingJava8Plus has no effect on look ahead anymore).

    142 seconds.

(4) Same commit as (2) + scanningJava8Plus force initialized to true +
Parser.atConflictScenario calls short circuited (presumed to always be true):

    145 seconds.

So it would appear that Parser.atConflictScenario saves us about 2%. No
big shakes, but given it is only 30 NCLOC, it looks worth it. Note that
these new measurements are against the new look ahead implementation. It 
could be that the new look ahead mechanism based on the VanguardParser is
slightly more expensive than plain looping in scanner and so the gating
policy yields ~2% savings vs ~0% earlier.

Just for kicks, I instrumented the scanner to gather some stats as it
ran TestAll (1.3 - 1.8, a total of 13254 test points against the commit
fa76c3ec72ce5ca3743ba534e916cc81952bcc4a "NOW"):

Total '(' :  115035, at conflict site:  32137 (27.9%)
Total '<' :   11284, at conflict site:   2340 (20.7%)

With generics heavy code, I would expect the latter to go up a good
bit, while the former may be representative already.


Bottomline: All set to close this, Only pending item is the review
for http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=e0956e75ff6cb3066016adc9dae90f9c1534dda4.
(In reply to comment #8)

> Fixing a typo and adding the tokens from the ternary operator, this 
> should read:
> 
>   PRECEDES(Lambda) = { "=", "return", "(", ")", ",", "->", "?", ":" }

It should read:

    PRECEDES(Lambda) = { "=", "return", "(", ")", ",", "->", "?", ":", "{" }

for  I i[] = { ()-> {} } is valid.
(In reply to comment #21)

> For '<' we will look ahead at every instance of it following an identifier.
> As mentioned in comment#17, JSR308 annotations make it impossible for a DFA
> to be constructed to serve as an oracle (since counting is required to know
> when annotation tokens end and a DFA cannot count)

I'll surely be accused of, and will certainly be guilty as charged of 
over-engineering this thing: While it is impossible to construct a DFA
to answer if look ahead is needed on a '<', turns out it is a much easier
question to answer if look ahead is NOT needed. All we need is to do is
to maintain a two token history buffer and most occurrences of '<' can
be disqualified as being a part of reference expression trunk.

Primary incentive is that if the cost of lookahead can be brought down
to near zero, then we can look ahead in all modes and solve bug 381358
automatically. 

Patch to follow :)
Created attachment 218808
Further tweaks to minimize look ahead.

In this patch, the scanner implements a notion of viable prefixes
to eliminate look ahead.

Some statistics: (TestAll 1.3 - 1.8 modes):

Total '(' :                115035 (100%)
After pruning by scanner :   4220  (3.7%)
After pruning by parser :     986  (0.9%)  <<- Look ahead needed

Total '<' :                  11284 (100%)
After pruning by scanner:     4380  (39%)
After pruning by parser        574  (5%)  <<-- Look ahead needed for these
I made some measurements closer to the worst case scenario to get a better picture of the differences. I identified a test case with high number of tokens look-ahead:

In GenericDietRecoveryTest.test0020() the VanguardScanner consumes max 15 tokens before the parser could reject the input

I used current head from master and added these configuration options:

USE_MAGIC:
- used in Scanner.getNextToken() en lieu de this.scanningJava8Plus

DETECT_CONFLICT:
- when true, atConflictScenario() is used, otherwise assume Vanguard
  is always needed.

The test ran these loops:
	for (int i=0;i<10000;i++)
		checkParse(...); // warm-up
	for (int i=0;i<10;i++) {
		long start = System.currentTimeMillis();
		for (int j=0;j<2000;j++)
			checkParse(...);
		System.out.println(System.currentTimeMillis()-start);
	}

Each print-out was in the order of 1000 ms. I discarded some test runs with std. deviation > 10 (1%).

The results are:

(1) USE_MAGIC=false; DETECT_CONFLICT=false;
 -> average = 1047.6

(2) USE_MAGIC=false; DETECT_CONFLICT=true;
 -> average = 1045.9

(3) USE_MAGIC=true; DETECT_CONFLICT=false;
 -> average = 1373.2

(4) USE_MAGIC=true; DETECT_CONFLICT=true;
 -> average = 1262.8

Interpretation:

(1) is the old setup, used as 100% in comparison.

(2) never use vanguard, but before (not) doing so check for conflict
    should be marginally more expensive than (1), actually ranked at 99.8%

(3) means always use vanguard, i.e., this is most expensive: 131% time

(4) shows the advantage of using atConflictScenario(): 121% time
    or: 92% of the time used for (3)


Since this is closer to a micro-benchmark than to a real-world experiment, the penalties of 21% or 31% should be taken with a grain of salt. The main message I see is: of all the overhead caused by look-ahead, 1/3 can be reduced using atConflictScenario(), thus clearly answering "yes" to my original question whether this method is worth its price.

Despite the carefully chosen test and the number of runs, one factor is still quite arbitrary: The ratio at which atConflictScenario(), when used, answered true vs. false. I only checked this after the experiment:
  atConflictScenario() answered true 36 times, false 1133 times per compile
Maybe this ratio is the major weakness in my experiment. So, for ultimate reliability one *might* want to combine this experiment with the findings from comment 29, but I'm fine with deferring further measurements towards the end of the Java 8 endeavor, to add some end-to-end measurements. At that time I'd like to tune the experiment so that we get a small enough std.dev. so that we can actually see into the 1-2% range.

We've seen that in total numbers of realistic application the differences are small, and we've seen that the extra smartness is worth its price. Sounds good to me for now.
Thanks Stephan. Could you mark the review flag for completeness ? TIA.

(In reply to comment #29)
> Created attachment 218808 [details]
> Further tweaks to minimize look ahead.
> 
> In this patch, the scanner implements a notion of viable prefixes
> to eliminate look ahead.

Released via http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=39fac05fa8b77fcaf96c0cb04f6cdf322c685cfd
(In reply to comment #31)
> Thanks Stephan. Could you mark the review flag for completeness ? TIA.
> 
> (In reply to comment #29)
> > Created attachment 218808 [details]
> > Further tweaks to minimize look ahead.
> > 
> > In this patch, the scanner implements a notion of viable prefixes
> > to eliminate look ahead.
> 
> Released via
> http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=39fac05fa8b77fcaf96c0cb04f6cdf322c685cfd

Hm, I didn't even see this patch until after my latest experiments. Should I review that, too?
(In reply to comment #32)

> Hm, I didn't even see this patch until after my latest experiments. Should I
> review that, too?

By all means. It should be very straightforward. TIA.
Cleaning stale review flag to +1 :)
