The grammar changes to support JSR 335 come under three heads
relative to the JLS7 grammar.

(1) Lambda expressions:
-----------------------

PrimaryNoNewArray:  
  LambdaExpression

LambdaExpression:
  LambdaParameters '->' LambdaBody

LambdaParameters:
  Identifier
  '(' FormalParameterListopt ')'
  '(' InferredFormalParameterList ')'

InferredFormalParameterList:
  Identifier
  InferredFormalParameterList ',' Identifier

LambdaBody:
  Expression
  Block

(2) Method and constructor reference expressions:
------------------------------------------------

PrimaryNoNewArray:
  MethodReference
  ConstructorReference

MethodReference:
 ExpressionName '::' NonWildTypeArgumentsopt Identifier
 Primary '::' NonWildTypeArgumentsopt Identifier
 ReferenceType '::' NonWildTypeArgumentsopt Identifier

ConstructorReference:
 ClassType '::' NonWildTypeArgumentsopt 'new'


(3) Default methods aka Virtual extension methods aka Defender methods
 
(a) Change JLS7 production

InterfaceMemberDeclaration:  AbstractMethodDeclaration  ';'

into 

InterfaceMemberDeclaration:  InterfaceMethodDeclaration';'

where

(b) 
InterfaceMethodDeclaration:
  InterfaceMethodModifiersopt TypeParametersopt Result
                      MethodDeclarator Throwsopt InterfaceMethodBody

InterfaceMethodModifiers:
  InterfaceMethodModifier
  InterfaceMethodModifiers InterfaceMethodModifier

InterfaceMethodModifier:
  Annotation 'public' 'abstract' 'strictfp' 'synchronized'

InterfaceMethodBody: 'default' Block';'


(c) Change JLS7 production
MethodInvocation:
  ClassName '.' 'super' '.'
          NonWildTypeArgumentsopt Identifier '(' ArgumentListopt ')'

into 

MethodInvocation:
  TypeName '.' 'super' '.'
          NonWildTypeArgumentsopt Identifier '(' ArgumentListopt ')'


(d) Change JLS7 production

AnnotationTypeElementDeclaration:
  AbstractMethodModifiersopt 
            Type Identifier '(' ')' Dimsopt DefaultValueopt ';'

into 

AnnotationTypeElementDeclaration:
  InterfaceMethodModifiersopt
            Type Identifier '(' ')' Dimsopt DefaultValueopt ';'


I'll shortly post the massage version that uses jikespg notation
as well as altered grammar symbols as we use in ECJ grammar so
it could be copy + pasted and experimented with.

The grammar changes to support JSR 335 come under three heads
relative to the JLS7 grammar.

(1) Lambda expressions:
-----------------------

PrimaryNoNewArray:  
  LambdaExpression

LambdaExpression:
  LambdaParameters '->' LambdaBody

LambdaParameters:
  Identifier
  '(' FormalParameterListopt ')'
  '(' InferredFormalParameterList ')'

InferredFormalParameterList:
  Identifier
  InferredFormalParameterList ',' Identifier

LambdaBody:
  Expression
  Block

(2) Method and constructor reference expressions:
------------------------------------------------

PrimaryNoNewArray:
  MethodReference
  ConstructorReference

MethodReference:
 ExpressionName '::' NonWildTypeArgumentsopt Identifier
 Primary '::' NonWildTypeArgumentsopt Identifier
 ReferenceType '::' NonWildTypeArgumentsopt Identifier

ConstructorReference:
 ClassType '::' NonWildTypeArgumentsopt 'new'


(3) Default methods aka Virtual extension methods aka Defender methods
 
(a) Change JLS7 production

InterfaceMemberDeclaration:  AbstractMethodDeclaration  ';'

into 

InterfaceMemberDeclaration:  InterfaceMethodDeclaration';'

where

(b) 
InterfaceMethodDeclaration:
  InterfaceMethodModifiersopt TypeParametersopt Result
                      MethodDeclarator Throwsopt InterfaceMethodBody

InterfaceMethodModifiers:
  InterfaceMethodModifier
  InterfaceMethodModifiers InterfaceMethodModifier

InterfaceMethodModifier:
  Annotation 'public' 'abstract' 'strictfp' 'synchronized'

InterfaceMethodBody: 'default' Block';'


(c) Change JLS7 production
MethodInvocation:
  ClassName '.' 'super' '.'
          NonWildTypeArgumentsopt Identifier '(' ArgumentListopt ')'

into 

MethodInvocation:
  TypeName '.' 'super' '.'
          NonWildTypeArgumentsopt Identifier '(' ArgumentListopt ')'


(d) Change JLS7 production

AnnotationTypeElementDeclaration:
  AbstractMethodModifiersopt 
            Type Identifier '(' ')' Dimsopt DefaultValueopt ';'

into 

AnnotationTypeElementDeclaration:
  InterfaceMethodModifiersopt
            Type Identifier '(' ')' Dimsopt DefaultValueopt ';'


I'll shortly post the massage version that uses jikespg notation
as well as altered grammar symbols as we use in ECJ grammar so
it could be copy + pasted and experimented with.
Adding Stephan and Olivier to CC list as I'll be requesting for
a review of grammar changes when they become available.

The straightforward massaging of the JLS8 grammar into Jikes
Parser Generator's preferred form results in an input that results
in various shift/reduce and reduce errors.

Here are some techniques being tried out:

1. When the grammar or a portion thereof rooted at non-terminal H
   results in parsing conflicts, transform H to H' where H and H' 
   are equivalent and H' is LALR(1) - the most obvious approach.
   There are various tricks to handle the common "patterns" of
   shift/reduce and reduce/reduce conflicts.

   It needs to ascertained whether the language described is 
   essentially/intrinsically non LALR(1), if so, this approach
   is not going to solve the problem fully.

2. When the grammar or a portion thereof rooted at non-terminal H
   results in parsing conflicts, transform H to H' where the set of
   strings in the language described by H' is a superset of the set
   of strings in H and the transformation results in overall LALR(1)
   grammar. Downstream phases should accept the burden of rejecting 
   the delta correctly and ought to be able to reject the delta 
   correctly.

3. Alternately burden the upstream component(s) - in this case the
   scanner with the task of disambiguating the input a la the 
   typedef vs identifier conflict in ANSI C grammar or the 
   procedure name vs array name in fortran (which uses () for both
   calls and array indexing). (analogous to how JLS8 ends up using
   () in three different constructs any of which can appear in the
   same context : (typecastedType), (expression) (lambdaParameterList)

4. When we have to plugin a LALR(1) sub-grammar into a presently
   LALR(1) grammar and the act of merging the grammars makes the
   overall grammar non LALR(1), one plausible approach is to when
   expecting to reduce the fragment grammar, preserve the parser
   state, reset the automaton's goal to the start state of the fragment
   grammar and upon successful reduction of the input fragment
   to the altered start state, restore the parser state and
   continue. This plays out nicely with the bottom up tree building
   process that naturally results from LR parsing.

5. Such rendezvous can be implemented alternately by interfacing
   hand written parser code with the generated automaton.

6. Generate a parser using a slightly different grammar such that
   no input string will be from the language (e.g by encoding the
   grammar with synthetic terminals) and make the parser detect
   and repair "errors" in the (valid) input stream to produce a
   valid parse. The diagnose parser does many of these tricks
   to compute the program with the minimal hamming distance to
   report the most probable error. We will have to work with a
   much more stringent requirement that every legal program must
   result in a parse while every illegal string is rejected.

7. Many translator writing systems allow for disambiguating rules.
   For instance, if in a shift/reduce conflict, if shift produces
   the more natural parse (e.g: if (exp) then stmt else stmt),
   then using a suitable rule the programmer can guide the parse.
   It needs to be seen what our options (if any) are here with Jikes.

8. Worst case scenario: Toss out the current parser infrastructure
   and start over.

9. Other ideas here.

 
First order business is to

    - Assess suitability of some permutation/combination of
      (1) through (7) to avoid (8).

priorities in decreasing order of importance being

    - Come up with a solution that will accept and produce a valid
      parse for every legal input string S and reject every illegal
      input string S'.
    - Maintainable code, localized, well documented hacks (in the
      best sense of the term) where necessary.
    - Reasonable performance characteristics.
    - Good error recovery, leveragability for assist parser,
      diagnose parser etc. 

I believe I have identified the pieces of the puzzle to be solved
as far as the changes required to support item (1) of comment#0 
are concerned and am in the process of prototyping the solution.

Stay tuned.
Created attachment 216119
Scanner + Parser + AST changes for Lambda expressions.


    The attached patch contains the changes in

        - Scanner,
        - Parser,
        - AST construction phases of the compiler

    to support Lambda expressions. (First of three heads under which
    changes come in in JSR 335).

    This is work in progress, but I believe is in a good shape.

    Head 3 - Defended method related parser changes should be trivial.

    If method & constructor reference expressions could be parsed, we
    would be done.

    For the curious: You need to (1) apply the patch against a workspace
    upto date with respect to master, (2) Then take the grammar file,
    feed it through jikespg and take all the intermediate files produced
    and update the workspace with them (3) Refresh workspace.

    I'll write detailed design and implementation notes later in the week
    before asking for review.
(In reply to comment #0)

> (3) Default methods aka Virtual extension methods aka Defender methods

> InterfaceMethodBody: 'default' Block';'

That should actually read

  InterfaceMethodBody: 'default' Block'
                        ';'

Here are some notes on the grammar changes required to support
default methods. The draft spec calls for changing the JLS7
productions in the following manner:

// ------------------
(a) Change JLS7 production

InterfaceMemberDeclaration:  AbstractMethodDeclaration  ';'

into 

InterfaceMemberDeclaration:  InterfaceMethodDeclaration';'


(b) Add new productions 
InterfaceMethodDeclaration:
  InterfaceMethodModifiersopt TypeParametersopt Result
                      MethodDeclarator Throwsopt InterfaceMethodBody

InterfaceMethodModifiers:
  InterfaceMethodModifier
  InterfaceMethodModifiers InterfaceMethodModifier

InterfaceMethodModifier:
  Annotation 'public' 'abstract' 'strictfp' 'synchronized'

InterfaceMethodBody: 'default' Block';'

// -------

The net effect of the above two changes is that 

(1) An interface method may now (syntactically) carry the
modifiers strictfp and synchronized - This is a NOP for us
since we anyways allow these modifiers already - i.e the
legality or lack thereof of a certain modifier was enforced
during semantic analysis and not constrained at the grammar
level.

(2) An interface method may have a body prefixed by default.
We already allow body for interface methods (again at the
grammar level rejecting it downstream) - now we need to allow
the body to be prefixed by 'default'.
 
//  ---- 

(c) Change JLS7 production
MethodInvocation:
  ClassName '.' 'super' '.'
          NonWildTypeArgumentsopt Identifier '(' ArgumentListopt ')'

into 

MethodInvocation:
  TypeName '.' 'super' '.'
          NonWildTypeArgumentsopt Identifier '(' ArgumentListopt ')'


(d) Change JLS7 production

AnnotationTypeElementDeclaration:
  AbstractMethodModifiersopt 
            Type Identifier '(' ')' Dimsopt DefaultValueopt ';'

into 

AnnotationTypeElementDeclaration:
  InterfaceMethodModifiersopt
            Type Identifier '(' ')' Dimsopt DefaultValueopt ';'

// ------

(c) and (d) are NOPs for us since our grammar is more permissive
and relies on downstream phases to enforce constrains and prune
illegal programs  - e.g at the grammar level we don't distinguish
between the different classes of names, i.e no different productions
for TypeName vs ClassName etc.

Again as per above, we don't constrain modifier legality at the
grammar level so (d) is a NOP too.

---------------------

Net grammar change is to just allow default prefixed bodies.
(In reply to comment #2)
> Created attachment 216119 [details]
> Scanner + Parser + AST changes for Lambda expressions.
> ...
>     This is work in progress, but I believe is in a good shape.

Congratulations! So we have hope that we can keep our parser, right? :)

The grammar-changes actually look very concise, cool!

The tricky part is in the Scanner, right?
(In reply to comment #5)
> (In reply to comment #2)
> > Created attachment 216119 [details]
> > Scanner + Parser + AST changes for Lambda expressions.
> > ...
> >     This is work in progress, but I believe is in a good shape.
> 
> Congratulations! So we have hope that we can keep our parser, right? :)

At this point, I would say that there is grounds for cautious optimism
that we don't have to toss the existing machinery out and start over.
Early next week, I hope to have a working implementation for all three
parts of JSR 335 (lambda, method/ctor references & defender methods).
We will know for sure soon ! (We also need to make sure the 335 changes
combined with the 308 changes still stay LALR(1))

Parts of the initial implementation would look unorthodox when viewed
relative to existing infrastructure. But if it works, it would at least
show that there is a solution. The good news is the complexity nowhere
approaches the hairy levels seen in some C++ compilers.

I'll consume your congratulations and thanks you for them after the
changes stand scrutiny from your side :)

(heads up that a review request will come your way early next week)

> The tricky part is in the Scanner, right?

Among others yes. I'll write detailed design notes before review.
(In reply to comment #0)

> (2) Method and constructor reference expressions:
> ------------------------------------------------
> 
> PrimaryNoNewArray:
>   MethodReference
>   ConstructorReference
> 
> MethodReference:
>  ExpressionName '::' NonWildTypeArgumentsopt Identifier
>  Primary '::' NonWildTypeArgumentsopt Identifier
>  ReferenceType '::' NonWildTypeArgumentsopt Identifier

Points to note:

    - The JLS7 ReferenceType non terminal maps to ECJ's ClassOrInterfaceType
and NOT to the latter's homonymous rule.

    - JLS7's rule NonWildTypeArguments maps to ECJ's OnlyTypeArguments rule.

    - We can merge method references and constructor references under the
same rules.

    - The first rule of MethodReference viz
          ReferenceType '::' NonWildTypeArgumentsopt Identifier
      is superfluous as it is covered by the third rule anyway.

So the concise & equivalent ECG grammar could be:

// ---------------------------------------
PrimaryNoNewArray -> ReferenceExpression

ReferenceExpression ::= Primary '::' NonWildTypeArgumentsopt Identifier
ReferenceExpression ::= ClassOrInterfaceType '::' NonWildTypeArgumentsopt IdentifierOrNew

NonWildTypeArgumentsopt -> $empty
NonWildTypeArgumentsopt -> OnlyTypeArguments

IdentifierOrNew -> 'Identifier'
IdentifierOrNew -> 'new'
// ----------------------------------------

Neither the JLS7 fragment nor the ECJ equivalent is LALR(1)
of course and will need to worked at. Basically there is a need
to disambiguate the use of '<' as the less than operator vs the
marker for type arguments list.
Created attachment 216326
Revised patch


    This patch is much further along. It has the prototype grammar changes
for all of JSR335, but reference expressions cannot yet be tested due to
some non grammar support that is still coming.
Created attachment 216338
Revised patch


    - Cleaned up and polished patch. 
    - Passes all JDT/Core tests.
    - Parsing support for ReferenceExpressions still in the works.
Created attachment 216390
Patch v1.0


    This patch contains a full & complete implementation of changes in

    - Scanner,
    - Parser and
    - AST construction phases.

    to support all of JSR 335: 

    - Lambda Expressions,
    - Method & Constructor references,
    - Defender methods.

    At this point, 

    - All existing JDT/Core tests pass.
    - All code snippets from the draft spec v0.5 (~May 15th 2012) 
      get parsed correctly.
    - The grammar changes for 335 + 308 still stay LALR(1).

This conclusively establishes that ECJ's existing parser technology
infrastructure can readily handle Java 8 changes and the worst case
scenario referred to in comment#1 point#8 can be averted altogether.

After completing one round of self review, I'll release the code in
BETA_JAVA8 branch and ask for code reviews and verification to be
undertaken by the team.
Released into BETA_JAVA8 branch via commit http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?id=c0fbf538c56e049473d6298631299cfef92195c1

Olivier, if you could find the time to review the changes at a high level 
that would be super. Since I plan to request Stephan for a detailed line
level review, it is enough if you restrict your high level review to:

    - java.g changes.
    - Parser.parserAtConflictScenario
    - Parser.getNextToken
    - Parser.consumeElidedLeftBraceAndReturn
    - Parser.consumeExpression()
    - Scanner.ungetToken
    - Scanner.getNextToken

of course you are welcome to review all. Design & implementation notes
will be posted shortly.
Stephan, could you please review the implementation ? Thanks.

A couple of notes on testing: 

    - Launch eclipse from a BETA_JAVA8 workspace and using Ctrl+Shift+R
      edit org.eclipse.jdt.core.prefs directly and add:

          org.eclipse.jdt.core.compiler.codegen.targetPlatform=1.8
          org.eclipse.jdt.core.compiler.compliance=1.8
          org.eclipse.jdt.core.compiler.source=1.8

      to enable use of JSR 335 constructs.

    - To shut up the downstream phases, I have arranged it so that the
      two new ASTNode types LambdaExpression and ReferenceExpression
      are subclassed from NullLiteral.
Satyam, If you manage to find the time for it, it would be great if you
could verify the implementation. You can start with enough of a review 
that will allow you to do some white box testing and augment it with 
some black box testing ... Thanks!

Here are some notes that will help in understanding the design 
and implementation:

The basic parsing complexity comes in the form of distinguishing 
between (a) the use of '<' as the less than operator from the use 
of '<' as the bracketing symbol for type argument list and (b) 
the use of '(' bracketing '(' Expression ')' and '(' TypeToCast ')' 
and '(' Lambda Parameter List ')'. 

The introduction of the new rules with these overloaded uses of 
tokens in the most "busy"  parts of the grammar (Expressions subgrammar)  
results in several shift/reduce and reduce/reduce conflicts.

Here are rules that cause conflicts and the solutions devised:
(I'll use the ECJ non-terminals in lieu of the JLS8 terminals
mentioned in comment#0)

(1) LambdaParameters -> '(' TypeElidedFormalParameterList ')'
    TypeElidedFormalParameterList -> Identifier
    TypeElidedFormalParameterList ::= TypeElidedFormalParameterList ',' Identifier

The straightforward incorporation of these rules results in shift/reduce
conflict on token class Identifier at a parser configuration that includes
these two items:

InferredFormalParameterList::= .Identifier 
Modifiersopt ::= . (516)

This conflict is easily resolved by making the parser accept a super set
of the input language that allows modifiers to be present for type elided
lambda parameters and then having the downstream phases reject programs
that do carry modifiers.

The altered productions read:

LambdaParameters ->  '(' TypeElidedFormalParameterList ')'
TypeElidedFormalParameterList -> TypeElidedFormalParameter
TypeElidedFormalParameterList ::= TypeElidedFormalParameterList ',' TypeElidedFormalParameter
TypeElidedFormalParameter ::= Modifiersopt Identifier

(2) The rules

LambdaParameters -> '(' FormalParameterListopt ')'
LambdaParameters -> '(' TypeElidedFormalParameterList ')'

result in several shift/reduce and reduce/reduce conflicts, basically
due to the straightforward incorporation of these rules leaving the
parser in an uncertain state upon seeing a '(' as to whether it is
seeing a parenthesized expression, or a type cast or a lambda expression.

This problem may be inherently unsolvable without requiring arbitrary
look ahead or at least may be very hard to do so while still managing
to retain the grammar in a form that is maintainable and amenable to 
proof of correctness - This needs to be studied further.

At the moment, the solution devised is to have the scanner look ahead
in the token stream, reaching past the matching ')' (balancing nested
'(' and  ')'s along the way) to see if it is followed by '->' and if so
inject a synthetic token BeginLambda ahead of the '('. The modified
rules look like:

LambdaParameters -> BeginLambda '(' FormalParameterListopt ')'
LambdaParameters -> BeginLambda '(' TypeElidedFormalParameterList ')'

where BeginLambda is a terminal symbol.

Naive and mindless implementation of this scheme could result in severe 
performance issues, so the implementation takes care to make sure that
the scanner looks ahead only when it absolutely must. E.g in the program
below, there is no need to look ahead at any of '(' since the positions 
at which '(' occur in the program below can never be the start of a lambda 
expression. And we don't look ahead at all while parsing this code.

// -------
public class X {
  public static void main(String[] args) {
    if (args == null) {
      System.out.println("All hell broke loose!");
    }
  }
} 
// -----------

We achieve this by tight and precise feedback and feedforth (Did I invent
that ?) between the parser and the scanner (more below.)  

(3) The rules implementing the ReferenceExpression subgrammar result
in many conflicts again due to the parser being uncertain as to whether
the token '<' signals the less than operator or whether it starts
type arguments as in '<' TypeArguments '>'.

We use the same technique as above and rely on the scanner to look ahead
and disambiguate by nudging & steering the parser gently into a configuration
where this ambiguity does not arise.

So the JLS8 rule which simply states

MethodReference: ReferenceType '::' NonWildTypeArgumentsopt Identifier

is first of all expanded into multiple rules by inlining the RHS for
ReferenceType (ECJ's ClassOrInterfaceType) and then we rewrite the
grammar to contain disambiguating synthetic terminals to arrive at:

ReferenceExpression ::= Name '::' NonWildTypeArgumentsopt IdentifierOrNew
ReferenceExpression ::= Name OnlyTypeArgumentsForReferenceExpression '::' NonWildTypeArgumentsopt IdentifierOrNew
ReferenceExpression ::= Name OnlyTypeArgumentsForReferenceExpression '.' ClassOrInterfaceType '::' NonWildTypeArgumentsopt IdentifierOrNew
ReferenceExpression ::= Primary '::' NonWildTypeArgumentsopt Identifier

OnlyTypeArgumentsForReferenceExpression -> BeginTypeArguments OnlyTypeArguments

where BeginTypeArguments is a synthetic token that the scanner is supposed
to fabricate and insert ahead of the '<'.

(4) The rule 

LambdaBody -> Expression 

results in many shift/reduce and reduce/reduce conflicts. Since a lambda
body of the form x is really '{' return x; '}', we transform the rule above
into:

LambdaBody -> ElidedLeftBraceAndReturn Expression ElidedSemicolonAndRightBrace

where ElidedLeftBraceAndReturn ::= $empty and ElidedSemicolonAndRightBrace
is again a synthetic terminal symbol.

This synthetic symbol is unlike the other two and is a bit more interesting
in that the scanner can never really determine when and where this symbol
must be inserted until after it is too late ! One token too many would need
to  have been consumed for the reduction into Expression to have taken place
and at the point the scanner cannot conveniently retract and change the tune.

We rely on the parser to detect, repair and recover from this situation as
follows:

If the input was:

    X x = p -> 10;

then the parser "expects" to see

Identifier(X), Identifier(x), Operator(=), Identifier(p), Operator(->),
Literal(10), ElidedSemicolonAndRightBrace, semicolon, 

but would actually see only

Identifier(X), Identifier(x), Operator(=), Identifier(p), Operator(->),
Literal(10), semicolon,

which would result in a "syntax error" due to "missing" expected symbol
ElidedSemicolonAndRightBrace.

As alluded to above, the scanner can never figure out by itself when to
concoct this artificial token and there is no timely feedback that can 
be devised (as opposed to the scenarios (2) and (3) above) from the parser's
side also. Until "Expression" has been reduced (and it can be reduced only
after seeing a subsequent token at which point it is too late), the parser
cannot signal to the scanner in any way the need to manufacture this symbol.

We solve this problem by having the parser track its state stack depths and
when the lambda's expression body is found to be reduced on the basis
of the the stack depths, then we push back the token that was consumed
"out of turn", switch the token to the terminal ElidedSemicolonAndRightBrace
and continue the parse.

This is a bit of sleight of hand, but a safe one to conjure since
at the point where the parser configuration indicates we are at the
state corresponding to the LR item

ElidedLeftBraceAndReturn Expression .ElidedSemicolonAndRightBrace

with the . positioned just to the left of ElidedSemicolonAndRightBrace,
the only possible legal token is ElidedSemicolonAndRightBrace and this
can never be returned by the scanner and the lambda is otherwise completely
syntactically correct. We thus "repair" the program of the "missing" 
token and recover.

A note about look ahead: As mentioned above it would be a non-starter
if the scanner has to look ahead at every '(' and every '<' to attempt to disambiguate. So the strategy implemented is as follows:

    - First of all, the look ahead happens only for 1.8+ source projects.
    - The scanner looks ahead only when asked to do so.
    - The parser requests the scanner to rescan the input by looking ahead
      only in those parser configurations where such disambiguation is
      absolutely necessary.

So the flow looks like this: In the following we use '( and ')' as
examples. Same argument holds for '<' and '>' and will not be called out
explicitly.

    - The scanner exposes a new API ungetToken(), which allows for
      a single token to be "pushed back". Only the most recently returned
      token can be safely ungotten.
    - The scanner also exposes a field shouldDisambiguate which is set
      to false normally. The parser can set this field to true to request
      the scanner to look ahead and disambiguate at the next call to 
      getNextToken
    - Upon encountering a '(', the scanner returns it to parser as it is
      (shouldDisambiguate being normally false)
    - Having been handed a '(' token, the parser checks its internal state
      to see whether it is at a configuration that could be the start of
      a lambda expression. If the answer is `no', then nothing further needs
      to happen and the '(' is indeed a '('.
    - If OTOH, the parser configuration indicates that a lambda expression
      would be a viable, then the parser pushes back the '(', requests
      disambiguation by temporarily setting shouldDisambiguate to true
      for the duration of the getNextToken call.
    - The scanner now looks ahead and either returns '(' itself signalling
      that '(' is indeed just '(' or inserts the synthetic symbol
      BeginLambda ahead of the pushed back '(' thereby nudging the parser
      into configurations where there is no ambiguity.

// ------------------------------------  

IMO, the implementation that has been prototyped has a high degree of
rigor and is eminently maintainable and something we can live with.

That said, since the first order business was to establish beyond all 
doubt that the existing parser technology infrastructure could indeed 
be extended to work with Java 8 changes, on occasions I may have jumped 
the gun to resort to unorthodox (relative to our infrastructure) techniques
altogether readily - Some or all of the issues listed above, may be
amenable to being solved via more canonical methods or standard 
treatment.

This task of identifying simpler solutions to some or all of the problems
can be undertaken during the review process as well as in a follow up
defect.
(In reply to comment #15)
> (4) The rule 
>
> LambdaBody -> Expression 

[...]

> We solve this problem by having the parser track its state stack depths and
> when the lambda's expression body is found to be reduced on the basis
> of the the stack depths, then we push back the token that was consumed
> "out of turn", switch the token to the terminal ElidedSemicolonAndRightBrace
> and continue the parse.

A good way to understand this technique is to to plant a breakpoint in
Parser.consumeExpression and debug this test case:

public class X {
  X x = (p) -> p != null ? 10 : 0; 
}

(Such nonsensical lambda expressions are "accepted" at this point
because every phase of the compiler past the AST construction is
effectively short circuited by the fact the new two AST node types
LambdaExpression and ReferenceExpression are subclassed from
NullLiteral precisely shut them up - In any case the above code
is syntactically legal)

In reducing  "p != null ? 10 : 0" into a ConditionalExpression using

ConditionalExpression ::= ConditionalOrExpression '?' Expression ':' ConditionalExpression

we first need to reduce 10 into Expression and this interim Expression
node itself should not be confused to be the lambda body. The state
stack depth tells us whether the reduction into Expression that we
are witnessing is the entire body of the most lexically recent
lambda expression or some interim node sets. 

Another case to debug that would help understand this code is:

public class X {
    X x = (a) -> (b) -> (c) -> (d) -> 10;
}
(In reply to comment #15)

> A note about look ahead: As mentioned above it would be a non-starter
> if the scanner has to look ahead at every '(' and every '<' to attempt to
> disambiguate. So the strategy implemented is as follows:
> 
>     - First of all, the look ahead happens only for 1.8+ source projects.
>     - The scanner looks ahead only when asked to do so.
>     - The parser requests the scanner to rescan the input by looking ahead
>       only in those parser configurations where such disambiguation is
>       absolutely necessary.

Another technique to minimize look ahead could be to arrange for the scanner
to look ahead only in assignment, method invocation or casting contexts as
everywhere else a lambda expression or a method reference or a constructor
reference is illegal.

There is a trade off here though: when lambda expressions are erroneously
used in other contexts, under this strategy we won't recognize them as such.
The program will most certainly be rejected as it should be, but not with
the best of error messages. The current strategy may suffer from this problem
to some extent already.
Support for new method reference production of the form:

MethodReference:
    'super' '::' NonWildTypeArgumentsopt Identifier

introduced in draft spec v0.5.1 added via:

http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?id=2f34b689f6a84d6509b412aba1f08255f656bb4e
Hello, a gentle reminder (no pressure) that this solution is pending
review for a couple weeks now. I know folks have been busy with RC3/RC4
related fixes and documentation work and other deliverables. Just the 
same, a mild nudge - consider yourself nudged :) 

If there is anything I can do in the way of additional explanations, 
clarifications etc, don't hesitate to ask.
I noticed you changed the nonterminal MethodReference into ReferenceExpression. Is there some scheme behind this / shouldn't we try to retain the original names as much as possible?
I'm done with a first pass through the explanations in comment 15,
at what time I want to confirm my congratulations!

The explanations are extremely helpful and from what I saw so far it all
makes perfect sense.

After building an understanding of the general design next I will search for
bugs / loopholes and anything fishy.

Has anyone done any performance measurements yet? E.g., how do the methods
Scanner.atLambdaParameterList() and Parser.parserAtConflictScenario() 
compare? Is the complexity of the latter worth the gain in avoiding calls
to the former?

Finally, I couldn't find any new unit tests. Forgotten to add to git?
Not yet done because we're waiting for the later phases of the compiler?
Created attachment 217578
bogus javadef.java from jikespg

I tried to re-generate all parser files which generally produced exactly
the same results as in git with one fishy exception:

I got quite different values in javadef.java (Snippet for 
ParserBasicInformation.java). Also some .rsc files differ.

When using my version the Parser throws AIOOBE.

My jikespg was installed from jikespg_1.3-1_i386.deb

Anything special to observe when generating the parser files this time?
Created attachment 217579
jikespg.log

Here's the output from the parser generator.
(In reply to comment #20)
> I noticed you changed the nonterminal MethodReference into ReferenceExpression.
> Is there some scheme behind this / shouldn't we try to retain the original
> names as much as possible?

We could, but as the spec draft mentions somewhere there is a sometimes
inconvenient and artificial dichotomy between methods and constructors
in java and subsequently we don't have a single term to speak of both.

I toyed with using MethodOrConstructorReference, but settled for ReferenceExpression as the nonterminal that will stand for both.
If you think retaining the split personality will improve grammar 
readability and help in the long run, please open a follow up defect.

(In general, for suggestions on improvements, let us use a follow up,
but any correctness issues let us address them "inline" in this bug)  

(In reply to comment #21)

> Has anyone done any performance measurements yet? E.g., how do the methods
> Scanner.atLambdaParameterList() and Parser.parserAtConflictScenario() 
> compare? Is the complexity of the latter worth the gain in avoiding calls
> to the former?

The catch here is the maximal worst case complexity we may have to deal
with on a '<' - since there is no guarantee that there will be a matching
'>' - the implementation already tries to "fail early" by short circuiting
the look ahead by using black lists, but I felt is better to look ahead only
when we must.

See also https://bugs.eclipse.org/bugs/show_bug.cgi?id=380194#c17 for
an alternate proposal to minimize look ahead. However, there *could*
be a catch there: In a rule like, 

CastExpression ::= PushLPAREN PrimitiveType Dimsopt PushRPAREN InsideCastExpression UnaryExpression

before we can conclude we are in a casting context, we would have consumed
one token too many.

You can debug this syntactically legal, but semantic garbage

    Object p = (Object) () -> 10;

to see what I mean. Also I shunned this approach since it requires me
to set flags from several different places.

Bottom line: I agree we should understand the performance characteristics
and suggest we do this in a follow up defect.

> Finally, I couldn't find any new unit tests. Forgotten to add to git?

I have been testing against workspace with numerous snippets. I'll role
in into a junit file before resolving current bug. Thanks!
Created attachment 217588
Output from jikespg 3.0

I am using 3.0 on windows - this is the output I am getting.

And here is the javadef file:


interface javadef
{
    public final static int

      ERROR_SYMBOL      = 115,
      MAX_NAME_LENGTH   = 41,
      NUM_STATES        = 1031,

      NT_OFFSET         = 115,
      SCOPE_UBOUND      = 144,
      SCOPE_SIZE        = 145,
      LA_STATE_OFFSET   = 13778,
      MAX_LA            = 1,
      NUM_RULES         = 746,
      NUM_TERMINALS     = 115,
      NUM_NON_TERMINALS = 335,
      NUM_SYMBOLS       = 450,
      START_STATE       = 792,
      EOFT_SYMBOL       = 67,
      EOLT_SYMBOL       = 67,
      ACCEPT_ACTION     = 13777,
      ERROR_ACTION      = 13778;
};


Looks like there is some sort of compression happening on the tables
in your version, that the rest of the infrastructure is not prepared
for.

So on master if you grab the grammar and generate the resource files
everything matches up ?
(In reply to comment #21)

> Has anyone done any performance measurements yet? E.g., how do the methods
> Scanner.atLambdaParameterList() and Parser.parserAtConflictScenario() 
> compare? Is the complexity of the latter worth the gain in avoiding calls
> to the former?

One further point about look ahead:

In the following:

x = Outer<One, Two>.Inner<Three, Four>.Deeper<Five, Six<String>>.Leaf::<Blah, Blah>method;

Given the grammar rule is :

ReferenceExpression ::= Name OnlyTypeArgumentsForReferenceExpression '.' ClassOrInterfaceType '::' NonWildTypeArgumentsopt IdentifierOrNew

only the '<' preceding "One" should be prefixed by the synthetic token
and not the ones preceding "Three" or "Five" - This can be too complicated
for a scanner to distinguish. But is guaranteed by the current implementation
since the parser will ask for disambiguation only when it is in a state
in which it could shift the synthetic token and not otherwise.
(In reply to comment #18)
> Support for new method reference production of the form:
> 
> MethodReference:
>     'super' '::' NonWildTypeArgumentsopt Identifier
> 
> introduced in draft spec v0.5.1 added via:
> 
> http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?id=2f34b689f6a84d6509b412aba1f08255f656bb4e

Due to a process glitch, this checkin was only partial and ineffective
and resulted in bug 383085. Now this condition has been rectified and
the full fix released via 

http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=fff49fd0bdbee760e61edee27f88554273119578.
(In reply to comment #26)
> (In reply to comment #21)

> One further point about look ahead:
> 
> In the following:
> 
> x = Outer<One, Two>.Inner<Three, Four>.Deeper<Five, Six<String>>.Leaf::<Blah,
> Blah>method;
> 
> Given the grammar rule is :
> 
> ReferenceExpression ::= Name OnlyTypeArgumentsForReferenceExpression '.'
> ClassOrInterfaceType '::' NonWildTypeArgumentsopt IdentifierOrNew
> 
> only the '<' preceding "One" should be prefixed by the synthetic token
> and not the ones preceding "Three" or "Five" - This can be too complicated
> for a scanner to distinguish.

For the record, it was not complicated to distinguish and this is relied
upon for the fix in the diagnose parser at the moment (see https://bugs.eclipse.org/bugs/show_bug.cgi?id=383046)
(In reply to comment #24)
> Bottom line: I agree we should understand the performance characteristics
> and suggest we do this in a follow up defect.

See bug 383378.
(In reply to comment #22)
> Created attachment 217578
> bogus javadef.java from jikespg
> 
> I tried to re-generate all parser files which generally produced exactly
> the same results as in git with one fishy exception:
> 
> I got quite different values in javadef.java (Snippet for
> ParserBasicInformation.java). Also some .rsc files differ.
> 
> When using my version the Parser throws AIOOBE.
> 
> My jikespg was installed from jikespg_1.3-1_i386.deb
> 
> Anything special to observe when generating the parser files this time?

By comparing the behavior of jikespg on two similar machines I found that this is a bug in jikespg: the tool (written in C) makes heavy use of statements like:
  strcpy(parm, parm + i);
but when consulting the docs for strcpy it says:
  The  strings  may  not overlap ...
or (different source):
  If copying takes place between objects that overlap, the behavior is undefined.
 
Apparently older versions of libc where implemented in a defensive manner, whereas the current Ubuntu ships a version that is true to the letter, producing "undefined behavior" as promised :-/

As a result several options could not be parsed which caused the diverging output.
Inserting this macro into lpgparse.c fixed the parser generator for me:

#define strcpy(d,s) bcopy(s,d,strlen(s)+1)

Changes in ParserBasicInformation.java are now down to only white space differences.

-----

On a similar note: I'm having differences re line ends in readableNames.props:
 - git: \r\n
 - local: \n

I seem to recall that all sources in git should have *nix line endings, no?

------

Finally, I see binary differences in parser21.rsc, cmp -l says:
 414  63   0
1486  63   0
2646  63   0
2654  63   0
2670  63   0
2686  63   0
2694  63   0
2702  63   0
2710  63   0

These differences actually cause a regression in 1.3 and 1.4 modes:
org.eclipse.jdt.core.tests.compiler.parser.ComplianceDiagnoseTest.test0041() reports:
 ----------\n
1. ERROR in X.java (at line 2)\n
	Z <Y1, for Y2> var;\n
	   ^^^^^^^^^^\n
Syntax error on tokens, delete these tokens\n
----------\n
where this is expected (see different length of highlighting):
----------\n
1. ERROR in X.java (at line 2)\n
	Z <Y1, for Y2> var;\n
	  ^^^^^^^^^^^^\n
Syntax error on tokens, delete these tokens\n
----------\n

Other than that I can now produce a working parser.
(In reply to comment #31)

> On a similar note: I'm having differences re line ends in readableNames.props:
>  - git: \r\n
>  - local: \n
> 
> I seem to recall that all sources in git should have *nix line endings, no?

Thanks, I'll look into this.

> Finally, I see binary differences in parser21.rsc, cmp -l says:
>  414  63   0
> 1486  63   0
> 2646  63   0
> 2654  63   0
> 2670  63   0
> 2686  63   0
> 2694  63   0
> 2702  63   0
> 2710  63   0
> 
> These differences actually cause a regression in 1.3 and 1.4 modes:
> org.eclipse.jdt.core.tests.compiler.parser.ComplianceDiagnoseTest.test0041()
> reports:

parser21.rsc is the compliance level table. This test is not failing for
me on BETA_JAVA top of branch - Is it failing for you "as is" on the branch
or does the failure happen when you generate the files locally on your system
and attempt to use them ?  

If you delete the tokens you are asked to delete you end up with

    Z <> var;

which is not a valid parse at all at 1.3/1.4. I also see that the rule 
that specifies the diamond syntax viz:

GenericType ::= ClassOrInterface '<' '>'
/.$putCase consumeGenericTypeWithDiamond(); $break ./
/:$readableName GenericType:/
/:$compliance 1.7:/

has a proper compliance setting. So it should not be tried at 1.3/1.4 levels
at all and it is a mystery why it would be.

You may want to plant a breakpoint in DiagnoseParser on the line*s* that
have the code:
if(Parser.rules_compliance[act] > this.options.sourceLevel) {

and see whether this rule above is indeed used in recovery and if so
what its compliance value is in the generated tables.

Also producing an ascii dump of the tables in the two versions and seeing if
there is a pattern for the changed entries may provide a clue.
(In reply to comment #32)

> and see whether this rule above is indeed used in recovery and if so
> what its compliance value is in the generated tables.

The generated file java.l can be used to discover the assignment of
numbers to rules.
(In reply to comment #31)
> -----
> 
> On a similar note: I'm having differences re line ends in readableNames.props:
>  - git: \r\n
>  - local: \n
> 
> I seem to recall that all sources in git should have *nix line endings, no?

Stephan, the line delimiters in git are \n and not \r\n. I had updated the tool which is used to update all parser files to make sure that  the delimiter is always \n. Can you please check again? Thanks!
(In reply to comment #34)
> (In reply to comment #31)
> > -----
> >
> > On a similar note: I'm having differences re line ends in readableNames.props:
> >  - git: \r\n
> >  - local: \n
> >
> > I seem to recall that all sources in git should have *nix line endings, no?
> 
> Stephan, the line delimiters in git are \n and not \r\n. I had updated the tool
> which is used to update all parser files to make sure that  the delimiter is
> always \n. Can you please check again? Thanks!

Indeed the issue is only in master, where readableNames.props *has* 0x0d 0x0a line end (\r\n).
Maybe the file has not been committed after updating the tool?
In BETA_JAVA8 everything is OK (just 0x0a aka \n).
(In reply to comment #32)
> > Finally, I see binary differences in parser21.rsc, cmp -l says:
> > ...
> parser21.rsc is the compliance level table. This test is not failing for
> me on BETA_JAVA top of branch - Is it failing for you "as is" on the branch
> or does the failure happen when you generate the files locally on your system
> and attempt to use them ?

All this is only about differences between locally generated files and those from BETA_JAVA8.
With a fresh workspace checked out from BETA_JAVA8 there's no issues.
I'm just worried that generating the parser is not reproduceable!

 
> If you delete the tokens you are asked to delete you end up with
> 
> Z <> var;
> 
> which is not a valid parse at all at 1.3/1.4. I also see that the rule
> that specifies the diamond syntax viz:
> 
> GenericType ::= ClassOrInterface '<' '>'
> /.$putCase consumeGenericTypeWithDiamond(); $break ./
> /:$readableName GenericType:/
> /:$compliance 1.7:/
> 
> has a proper compliance setting. So it should not be tried at 1.3/1.4 levels
> at all and it is a mystery why it would be.

Because the compliance level is not correctly written to parser21.rsc.

I think I found the bug: The git version of Parser.buildFileForCompliance() cannot handle compliance > 1.5.
Adding these lines in the appropriate place fixes the table generation for me:

					} else if("1.7".equals(token)) { //$NON-NLS-1$
						compliance = ClassFileConstants.JDK1_7;

Srikanth, do you have another version of Parser.java that you used for generating the tables?
Otherwise the mystery is: why did this ever work?
(In reply to comment #36)
> I think I found the bug: The git version of Parser.buildFileForCompliance()
> cannot handle compliance > 1.5.
> Adding these lines in the appropriate place fixes the table generation for me:
> 
> } else if("1.7".equals(token)) { //$NON-NLS-1$
> compliance = ClassFileConstants.JDK1_7;
> 
> Srikanth, do you have another version of Parser.java that you used for
> generating the tables?
> Otherwise the mystery is: why did this ever work?

Along the same lines: the checked-in version of parser21.rsc doesn't seem to use compliance 0x340000 for 1.8.
Two more lines like the above are needed for 1.8!
(In reply to comment #36)

> I think I found the bug: The git version of Parser.buildFileForCompliance()
> cannot handle compliance > 1.5.

Indeed, for completeness sakes, I'll also add code for 1.6 and 1.8 modes.

> Srikanth, do you have another version of Parser.java that you used for
> generating the tables?

Yes, I used an internal tool that automates the steps (which has various
dependencies of different provenance that prevents it from being shared.)
My sincere apologies that this lack of proper update in the past and present
has caused this confusion and wasted time from your side. bug 383499 has
been raised to follow up on the issue.
(In reply to comment #38)
> Yes, I used an internal tool that automates the steps (which has various
> dependencies of different provenance that prevents it from being shared.)

In the Object Teams project we have this script:
http://git.eclipse.org/c/objectteams/org.eclipse.objectteams.git/tree/org.eclipse.jdt.core/scripts/generateOTParser.sh
which basically automates the steps from the "how to generate the parser".

But then I assume this is of little help for you as all of you are working on windows, right?

> My sincere apologies ...

no need to apologize, it's just the necessary dose of bugs to keep the reviewer awake :)

I was actually more startled by the bug in jikespg (comment 30 fix in comment 31).
(In reply to comment #14)

> Satyam, If you manage to find the time for it, it would be great if you
> could verify the implementation. You can start with enough of a review 
> that will allow you to do some white box testing and augment it with 
> some black box testing ... Thanks!

@Ayush, As Satyam couldn't finish this task, could you take this up 
please ? Black box testing is enough as Stephan is reviewing the design 
and  implementation anyways. TIA.

@Stephan, does 10th July sound reasonable for wrapping up the design & code
review ? Needless to say, we should focus on the thoroughness of review 
more than the date, so the date can be moved around if needed - Just trying
to get an ETA - No pressure.
(In reply to comment #0)

[...]

> InterfaceMethodModifier:
>   Annotation 'public' 'abstract' 'strictfp' 'synchronized'
> 
> InterfaceMethodBody: 'default' Block';'


[...]

> (d) Change JLS7 production
> 
> AnnotationTypeElementDeclaration:
>   AbstractMethodModifiersopt 
>             Type Identifier '(' ')' Dimsopt DefaultValueopt ';'
> 
> into 
> 
> AnnotationTypeElementDeclaration:
>   InterfaceMethodModifiersopt
>             Type Identifier '(' ')' Dimsopt DefaultValueopt ';'

The combined effect of these two is to allow annotation type members
to have strictfp and sychronized modifiers on them. However, we have
heard from the spec committee that this is the side effect of refactoring
and does not signal a real change: i.e 

"Nothing about annotation types changes, though, despite the grammatical
 change: 9.6.2 clarifies that annotation methods are _always_ abstract, 
and 9.4 asserts that the 'strictfp' and 'synchronized' keywords cannot
be used with abstract methods."
(In reply to comment #24)

> > Finally, I couldn't find any new unit tests. Forgotten to add to git?
> 
> I have been testing against workspace with numerous snippets. I'll role
> in into a junit file before resolving current bug. Thanks!

Test infrastructure changes released via 

http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=6ba0f0abfa6254bc0acf0eb26dd83c171f7e61b8 and

http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=2f0a591b08e4cab4a3fb7da43b28f0adc4c3a940

Tests will follow shortly.
(In reply to comment #42)

> Tests will follow shortly.

This dreadfully dreary and singularly unimaginative commit:

http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=834bb3df875d46fb3a9058f7e3e103441d8b1dab

should take care of exercising all the productions with various
optional components.

Stephan & Ayush, the ball is in your court for review and verification. TIA.
(In reply to comment #24)

> (In reply to comment #21)
> 
> > Has anyone done any performance measurements yet? E.g., how do the methods
> > Scanner.atLambdaParameterList() and Parser.parserAtConflictScenario() 
> > compare? Is the complexity of the latter worth the gain in avoiding calls
> > to the former?

> The catch here is the maximal worst case complexity we may have to deal
> with on a '<' - since there is no guarantee that there will be a matching
> '>' - the implementation already tries to "fail early" by short circuiting
> the look ahead by using black lists, but I felt is better to look ahead only
> when we must.

That is altogether overlooking the all too common scenario of parenthesis
imbalance: What happens if in a large otherwise syntactically valid file, 
early on there is a missing ')' ? We would scan all the way to EOF (assuming 
diet parsing is not in effect.) Of course, the imbalance could be at the
conflict scenario too :) We may need to build black lists for () also.

I am devising some measurements, stay tuned.
(In reply to comment #44)

> That is altogether overlooking the all too common scenario of parenthesis
> imbalance: What happens if in a large otherwise syntactically valid file, 
> early on there is a missing ')' ? We would scan all the way to EOF (assuming 

This got addressed via bug 384317.

> I am devising some measurements, stay tuned.

Comment#44 was posted here by mistake, the topic of performance of
scanner/parser due to 335 changes is dealt with in bug 383378
Please see two small side issues of the parser change: bug 384666 & bug 384667.
Method Scanner.getNextToken() has around 130 callers in my workspace.

Srikanth, do you have a simple story, why only 2 of these calls are
redirected via Parser.getNextToken() (to perform disambiguation)?

I don't easily see any other location where this would be needed, but
couldn't there be more locations that need this disambiguation?

Examples of locations that I'm uncertain about:
- Parser.moveRecoveryCheckpoint()
- LexStream.readTokenFromScanner()
- AbstractCommentParser.readToken()
- SelectionEngine.checkSelection()
(In reply to comment #47)
> Method Scanner.getNextToken() has around 130 callers in my workspace.
> 
> Srikanth, do you have a simple story, why only 2 of these calls are
> redirected via Parser.getNextToken() (to perform disambiguation)?

Yes. Only those layers that need to deal with the phrase structure of
the program should bother with disambiguation. That eliminates majority
of the callers.

> I don't easily see any other location where this would be needed, but
> couldn't there be more locations that need this disambiguation?

I'll run through the list of callers to see if there are any omissions.

> - LexStream.readTokenFromScanner()

I know this one is not an issue, since DiagnoseParser runs the scanner
in a always look ahead mode at 1.8+. See https://bugs.eclipse.org/bugs/show_bug.cgi?id=383046
Created attachment 218627
proposed comment changes

While inching along in the code review here are a few additions/changes of comments in Parser.java, which I'd consider helpful.

When all grammar changes are approved we might want to do a general update of those comments in Parser.java that show which grammar rules trigger a specific consume method.
Here's one thing that looks wrong to me:

The consumeReferenceExpression* group of methods uses getUnspecifiedReferenceOptimized() to get a SingleNameReference representing the Identifier.

By analogy to FieldReference and MessageSend I'd expect that the Identifier is handled by directly fetching the char[] from the identifierStack and storing it as-is (no wrapping with a SingleNameReference).

The reason I believe this will be relevant is how AssistParser & Co. hook into the process by overriding getUnspecifiedReferenceOptimized(). I don't have a test that shows that this is a problem, but wanted to ask for rationale behind the current implementation, first.
(In reply to comment #49)
> Created attachment 218627 [details]
> proposed comment changes
> 
> While inching along in the code review here are a few additions/changes of
> comments in Parser.java, which I'd consider helpful.

Thanks, 

> When all grammar changes are approved we might want to do a general update of
> those comments in Parser.java that show which grammar rules trigger a specific
> consume method.

Sounds good, will do.

(In reply to comment #50)
> Here's one thing that looks wrong to me:
> 
> The consumeReferenceExpression* group of methods uses
> getUnspecifiedReferenceOptimized() to get a SingleNameReference representing
> the Identifier.
> 
> By analogy to FieldReference and MessageSend I'd expect that the Identifier is
> handled by directly fetching the char[] from the identifierStack and storing it
> as-is (no wrapping with a SingleNameReference).

This appears possible - It is not like the current approach was chosen
after weighing in this alternate you cite. 

Stephan, could we assign number to issues/questions so we can tally up
more easily and know when we are done ? TIA.
Also there is some ambiguity in consumeReferenceExpressionNameForm(),
it is unclear that at the parser level we could tell apart a NameReference
from a TypeReference - this issue needs to be understood better.

X.Y::method : Is X.Y a type or a name ?
(In reply to comment #52)
> Also there is some ambiguity in consumeReferenceExpressionNameForm(),
> it is unclear that at the parser level we could tell apart a NameReference
> from a TypeReference - this issue needs to be understood better.
> 
> X.Y::method : Is X.Y a type or a name ?

I think using a NameReference for the prefix X.Y is correct. We'll have to decide during resolve which variant we have and set bits TYPE vs. VARIABLE accordingly, no?

I'm just wondering: since we'll have to check the NameReference for its kind any way, is it a good idea to have separate name / type fields in ReferenceExpression? I see two options:
- use one field of type Reference and use bits to decide how to handle this, or:
- let the Parser always create a NameReference and only use bits to distinguish (could be set in ctor of ReferenceExpression if we know it's a type).
The latter option may again conflict with AssistParsers: here it's good to use getTypeReference(0), so the AssistParser can kick in.

Following the idea to collate fields, why not do as we do in MessageSend: use just one field 'receiver' no matter if its a name, a type or any expression? (This would include also 'Expression primary').
(In reply to comment #51)
> Stephan, could we assign number to issues/questions so we can tally up
> more easily and know when we are done ? TIA.

Actually, given the quality of the patch I don't expect this number to rise high, but let's start anyway:

(1) Check callers of Scanner.getNextToken() for need to use Parser.getNextToken() (see comment 47)

(2) Comment changes from comment 49 plus re-sync Parser.java <-> java.g

(3) Check use of getUnspecifiedReferenceOptimized() for getting a simple Identifier (see comment 50)

(4) Decide fields of ReferenceExpression (only one of name/type/primary is used - see comment 53)


During the review I'm also writing a few additional tests. Do you want these as patches attached here, or should I simply push those to git?
(5) Parser has some comments indicating an interim solution:
 (a) consumeLambdaExpression() 
     // ')' position, discard for now 
     (see also bug 384667)
 (b) consumeReferenceExpressionNameForm()
     // Pop and drop dimensions as of now - there is some ambiguity between type reference and name reference here.
     I haven't checked the business of dimensions in this locations.
     Is this s.t. unfinished?
(In reply to comment #55)
> (5) Parser has some comments indicating an interim solution:
>  (b) consumeReferenceExpressionNameForm()
>      // Pop and drop dimensions as of now - there is some ambiguity between
> type reference and name reference here.
>      I haven't checked the business of dimensions in this locations.
>      Is this s.t. unfinished?

See also ReferenceExpressionSyntaxTest.test0017()

IN:
    I i = X[]::<String>clone;
EXPECTED OUT:
    I i = X::<String>clone;

Really?? :)

ReferenceExpression doesn't even have a field dims. Is this unfinished due to open issues regarding the spec?
(In reply to comment #54)

> During the review I'm also writing a few additional tests. Do you want these as
> patches attached here, or should I simply push those to git?

Either is fine. In the latter case, you could simply mention the commit ids
here.

(In reply to comment #56)

> IN:
>     I i = X[]::<String>clone;
> EXPECTED OUT:
>     I i = X::<String>clone;
> 
> Really?? :)

:) That's bad, thanks for catching it - I have reopened bug 381121.
(6) inside consumeReferenceExpressionTypeForm(), extract this line
       this.intPtr --; // pop '<' position
    from then and else branches 
    (I was wondering about the line without a comment ...)
(In reply to comment #54)

> (4) Decide fields of ReferenceExpression (only one of name/type/primary is used
> - see comment 53)

BTW, there is a survey afoot in the EG to decide whether the support for
"bound references" i.e those of the form the form expression::name should
be dropped leaving in only "unbound references" i.e those of the form
ReferenceType::name. The trade off is between implementation complexity vs
expressivity - in some quarters there is a perception bound references carry
with them a lot of extra complexity.
(7) Scanner.atLambdaParameterList() and atReferenceExpression() both call jumpOver(), which can modify unicodeAsBackSlash. It seems we'd need to store and restore this flag, too - or provide reasoning why this is not needed. 
However, *if* we decide we don't need parserAtConflictScenario() than also these two methods would go, right?
(In reply to comment #60)

> However, *if* we decide we don't need parserAtConflictScenario() than also
> these two methods would go, right?

Why/How ? Eliminating parserAtConflictScenario() would only mean that
disambiguation will shift from a do-it-on-demand mode to a do-it-always
basis. The question of whether the scanner should inject synthetic tokens
to nudge the parser out of conflict zones will still be keyed off these
methods.

Also at the moment, atReferenceExpression does not handle annotations.
I am working with the JSR 308 to get this clarified - I have heard
preliminary answers that annotations would be allowed only in the
type argument portion of a reference expression - which is good (it
works already), but it will get ugly if the 308 EG decides to allow
type annotations all over the place: e.g:

Outer.@ Annot Inner []@DimAnnot[][]
(In reply to comment #61)
> (In reply to comment #60)
> 
> > However, *if* we decide we don't need parserAtConflictScenario() than also
> > these two methods would go, right?
> 
> Why/How ? Eliminating parserAtConflictScenario() would only mean that
> disambiguation will shift from a do-it-on-demand mode to a do-it-always
> basis. The question of whether the scanner should inject synthetic tokens
> to nudge the parser out of conflict zones will still be keyed off these
> methods.

Sorry, I didn't really think how the code would change when we remove parserAtConflictScenario(). Just saw that this is the only location that explicitly checks for the synthetic tokens, forgot their occurrence in the grammar. Let's just delete the "*if*" part from (7).
(In reply to comment #57)
> (In reply to comment #54)
> 
> > During the review I'm also writing a few additional tests. Do you want these as
> > patches attached here, or should I simply push those to git?
> 
> Either is fine. In the latter case, you could simply mention the commit ids
> here.

I've pushed a few additional tests via commit 418d08685e8bc0508d05dda65dd277f56261854f
I'm about to declare "done" for the source review of the grammar/Parser/Scanner combo.

However, one method still resists my attempts of understanding: Scanner.jumpOver(), which goes deeper into unicode handling than I do in daily business :)

If you want me to do a detailed review of that method, I could use some help, either by a self-contained explanation, or by describing the delta wrt jumpOverMethodBody(), not sure which is easier.
(In reply to comment #64)

> If you want me to do a detailed review of that method, I could use some help,
> either by a self-contained explanation,

Here is what I suggest we do in parallel:

    - You can replace every pattern of the form 

if (((this.currentCharacter = this.source[this.currentPosition++]) == '\\')
								&& (this.source[this.currentPosition] == 'u')) {
    getNextUnicodeChar();
}

with 
    this.currentCharacter = this.source[this.currentPosition++]; 

having satisfied yourself that this pattern simply sets 
this.currentCharacter to the correct value should a unicode sequence 
be encountered at the cursor position.

That will unclutter the code quite a bit and allow for better focus.
And then you can ask about specific usages in specific case arms of
the switch.

    - From my side, I'll write a junit that will exercise the different
paths - so you will be able to plant a breakpoint on any code you want
to understand and see what input triggers it, why, and how it is handled.

>or by describing the delta wrt
> jumpOverMethodBody(), not sure which is easier.

An alternate way to handle this situation is to start with copy/pasting 
jumpOverMethodBody into a new method and start excising the portions
not needed to accomplish the scan ahead to the matching ')' or '>' and
see if you end up with what I ended up with - This is more work, so
we can do what is suggested above - it will also provide additional
test coverage -- I'll work on this Friday.
While the various ways the scanner tries to help the parser are
IMO, eminently maintainable, here is a proposal to inject maximal
rigor:

Borrowing the idea from comment#1 point (4), how about in a follow up 
defect, we replace the entire implementation of the method 
atLambdaParameterList() with a parallel parser-scanner pair that would
have a goal of reducing LambdaParameterList where

LambdaExpression ::= LambdaParameters '->' LambdaBody

LambdaParameters ::= Identifier

LambdaParameters -> BeginLambda LambdaParameterList 

LambdaParameterList ::= '(' FormalParameterListopt ')'
LambdaParameterList ::= '(' TypeElidedFormalParameterList ')'

and either the automaton enters an error state or if it reduces 
LambdaParameterList (which can happen only on token ->), then we
answer true.

Likewise, rewrite the present rules:

ReferenceExpression ::= Name OnlyTypeArgumentsForReferenceExpression Dimsopt '::' NonWildTypeArgumentsopt IdentifierOrNew

ReferenceExpression ::= Name OnlyTypeArgumentsForReferenceExpression '.' ClassOrInterfaceType Dimsopt '::' NonWildTypeArgumentsopt IdentifierOrNew 

to be 

ReferenceExpression ::= Name BeginTypeArguments ReferenceExpressionHeaderRest '::' NonWildTypeArgumentsopt IdentifierOrNew

ReferenceExpressionHeaderRest ::= OnlyTypeArguments Dimsopt 
ReferenceExpressionHeaderRest ::= OnlyTypeArguments '.' ClassOrInterfaceType Dimsopt 

That will eliminate all the code in the scanner today - atLambda*, atRefere*,
jumpOver() etc and replace it with a maximally rigorous implementation that
is also very small ?
(In reply to comment #66)
> While the various ways the scanner tries to help the parser are
> IMO, eminently maintainable, here is a proposal to inject maximal
> rigor:

If we combine this proposal with the cheap oracle that will answer
whether look ahead is required or not described in https://bugs.eclipse.org/bugs/show_bug.cgi?id=383378#c9 (assuming
that stands scrutiny) we can also drastically cut down on the
multiverses that need to simultaneously exist.
So Stephan, here is a plausible POA:

If the proposal in comment#66 and comment#67 sounds reasonable,
you cam skip review of jumpOver() and close the code review as
is. I'll implement the parallel parser/scanner driven implementation
of atLambda*() and  atReference*() in a follow up defect. If for
some reason that doesn't fly - we can revisit the review of this
method - does that sound good ? 

This would also address the annotation concern raised in comment# 61.
(In reply to comment #64)
> I'm about to declare "done" for the source review of the grammar/Parser/Scanner
> combo.
> 
> However, one method still resists my attempts of understanding:
> Scanner.jumpOver(), which goes deeper into unicode handling than I do in daily
> business :)

Alternate fix is under test in
https://bugs.eclipse.org/bugs/show_bug.cgi?id=385009 that completely eliminates
this method. If tests go well, we can
close the review on this (please remember to set the review flag), I'll move
all follow up comments to a separate bug and resolve this.
Comment on attachment 218627
proposed comment changes

Released via http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=bfac42801201b7609826716b3d7b2a4e81ff2e05
(In reply to comment #69)

> Alternate fix is under test in
> https://bugs.eclipse.org/bugs/show_bug.cgi?id=385009 that completely eliminates
> this method. If tests go well,

All tests are green. Let us prepare to resolve this defect:

    - https://bugs.eclipse.org/bugs/show_bug.cgi?id=385041 has been raised
as follow up and all open issues moved to there.

Stephan: Things pending from you:

    - Review of fix for bug 385009 in lieu of jumpOver().
    - Update review flag. 

Ayush: Things pending from you:

    - Update on status of verification.

Srikanth: To close defect.
(In reply to comment #71)
> (In reply to comment #69)
> 
> > Alternate fix is under test in
> > https://bugs.eclipse.org/bugs/show_bug.cgi?id=385009 that completely eliminates
> > this method. If tests go well,
> 
> All tests are green. Let us prepare to resolve this defect:
> 
>     - https://bugs.eclipse.org/bugs/show_bug.cgi?id=385041 has been raised
> as follow up and all open issues moved to there.

Great, I'll take a look.
So item (7) would be resolved by the other bug.

Could you please summarize the status on items (1) - (6) (comment 54 ff)?
> (In reply to comment #72)
> Could you please summarize the status on items (1) - (6) (comment 54 ff)?

Sorry, I asked in a hurry, didn't realize that bug 385041 *is* the answer to my question. Oops.
See up to date performance numbers posted at 
https://bugs.eclipse.org/bugs/show_bug.cgi?id=383378#c26.

We are all set to close this. Only pending items are:

    - Review of http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=e0956e75ff6cb3066016adc9dae90f9c1534dda4 (bug 383378) and
    - Review of http://git.eclipse.org/c/jdt/eclipse.jdt.core.git/commit/?h=BETA_JAVA8&id=2d42c7f71ce65658f51f1f08922e1c6e3b9d54f4 (bug 385009)

    - Non blocker follow ups addressed via separate train at bug 385041
Not a blocker, but a small new catch: bug 385132.
A few general remarks:

The grammar change (in conjunction with the 308 work) introduced some new methods not respecting the typical alphabetic order. IF this order shall be re-established at some point in time, PLEASE do so in one dedicated, clearly marked commit that carries no other changes. I'm not overly worried about alphabetic order, but merging a sort member action into a relevant commit could cause considerable havoc when working with this history later. From the pov of creating a clean history I would actually prefer to leave the order as it is now.


While reviewing the grammar changes for JSR 305 I started by taking a diff that indeed only contains changes contributing to this. However, meanwhile the history has all of the JSR 308 work interspersed with JSR 305. This means during my reviewing I also glanced at some 308 related changes, but I can no longer assure that I've scrutinized every single code change. I guess I'm just saying that we need very good test coverage in addition to the code review, because neither has a chance of being complete :)
It seems the spec allows nested method references
   X::foo::bar
And so does our grammar.

I can only find one rule that indicates that this is an error:
"15.28  It is a compile-time error if a method or constructor reference expression occurs in a program in someplace other than an assignment context (5.2), an invocation context (5.3), or a casting context (5.5)."

If I interpret this correctly, then we are to report an error like this:
  I i = X::foo::bar;
        ^^^^^^
Method reference is not allowed here, legal contexts are assignment, ..."

This looks like we will run into difficulties explaining to users that X::foo is *not* in an assignment context here (since it's the primary in the enclosing method reference to "bar").

Might be worth consultation with the EG, whether the above should instead be signaled as a syntax error?

I guess the following is indeed legal, right?
  I1 i1 = ((I2) x::foo)::bar;

The rules in question are:

Primary -> PrimaryNoNewArray
PrimaryNoNewArray -> ReferenceExpression
ReferenceExpression ::= Primary '::' NonWildTypeArgumentsopt Identifier
(In reply to comment #76)

> From the pov of
> creating a clean history I would actually prefer to leave the order as it is
> now.

Agree with the point about separate commit & test coverage, 

No plans to sort members - we will leave it as is.

> during my reviewing I also glanced at some 308 related changes, but I can no

The bulk of the 308 grammar (and other) changes have had the benefit of 
another pair of eyes scrutinizing them already. I have had to make some 
changes recently for (a) receiver annotations, (b) class literals and 
(c) a change for annotations on nested types is in progress. 

That should conclude the changes for the two JSRs (ignoring recovery/error
productions for the moment)
(In reply to comment #77)
> It seems the spec allows nested method references
>    X::foo::bar
> And so does our grammar.
> 
> I can only find one rule that indicates that this is an error:
> "15.28  It is a compile-time error if a method or constructor reference
> expression occurs in a program in someplace other than an assignment context
> (5.2), an invocation context (5.3), or a casting context (5.5)."
> 
> If I interpret this correctly, then we are to report an error like this:
>   I i = X::foo::bar;
>         ^^^^^^

Yeah I caught this as well, but I think the grammar should allow this (looking at the proposed changes in JLS). Only during the semantic analysis phase should we reject it. We can record this in bug 382701
For the record, I have completed my testing of the grammar changes and besides minor issues, no major problem was found.
(In reply to comment #80)
> For the record, I have completed my testing of the grammar changes and besides
> minor issues, no major problem was found.

Thanks a lot Ayush !
(In reply to comment #79)

> Yeah I caught this as well, but I think the grammar should allow this (looking
> at the proposed changes in JLS). Only during the semantic analysis phase should
> we reject it. We can record this in bug 382701

Why wouldn't this happen automatically ?
(In reply to comment #82)
> (In reply to comment #79)
> 
> > Yeah I caught this as well, but I think the grammar should allow this (looking
> > at the proposed changes in JLS). Only during the semantic analysis phase should
> > we reject it. We can record this in bug 382701
> 
> Why wouldn't this happen automatically ?

Which "this"? :)

I'd anticipate that "automatically" we'd raise the error:

  "Method reference is not allowed here, legal contexts are assignment, ..."

which I'd consider a poor explanation, since this *is* in an assignment,
just invisibly nested in the other method reference.
(In reply to comment #83)
> (In reply to comment #82)
> > (In reply to comment #79)
> > 
> > > Yeah I caught this as well, but I think the grammar should allow this (looking
> > > at the proposed changes in JLS). Only during the semantic analysis phase should
> > > we reject it. We can record this in bug 382701
> > 
> > Why wouldn't this happen automatically ?
> 
> Which "this"? :)
> 
> I'd anticipate that "automatically" we'd raise the error:
> 
>   "Method reference is not allowed here, legal contexts are assignment, ..."
> 
> which I'd consider a poor explanation, since this *is* in an assignment,
> just invisibly nested in the other method reference.

I think the context is just fine, (though javac complains "method 
reference not expected here") the error should be about the target
method for lambda conversion, no ? The first reference expression
serves as a primary and provides a reference type for the subsequent
reference expression, no ?
The way I read the spec the 'inner' reference X::foo cannot be type checked because no expected type can be inferred from the context.

Isn't that what 15.28 says?
For completeness: I believe the current implementation using VanguardParser etc. is a very systematic implementation with about the minimal overhead that any look-ahead based strategy can have.

FOR THE CASE even that small overhead should be avoided, I'm fancying a plan C that would avoid any look-ahead. But I don't want to dive into this if it has been considered already. I'm thinking of this:

Take the lambda parameter list as an example, which conflicts with normal paranthesized expressions. Would it be possible to factor out a prefix, which is a super set of what both branches accept, let the parser create some expression-like AST and if later a '->' is encountered transform the expression into an equivalent lambda, doing part of the syntax analysis during this transformation. S.t. like:

UnknownPrefix -> PushLPAREN LambdaArgOrExpression

LambdaArgOrExpression ::= Modifiersopt Name
/.$putCase consumeUnknownName(); $break ./
-- create AST without knowing what it really represents

LambdaArgOrExpression ::= FormalParameter
/.$putCase consumeLambdaParameter(); $break ./

NormalExpressionOrLambda ::= UnknownPrefix PushRParen
/.$putCase consumeParenthesizedName(); $break ./
-- checks if the top of the stack holds a legal expression

NormalExpressionOrLambda ::= UnknownPrefix PushRParen '->' LambdaBody
/.$putCase consumeLambdaExpression(); $break ./
-- here we reject prefixes that cannot be re-interpreted as a formal param

NormalExpressionOrLambda ::= UnknownPrefix ',' LambdaTail

LambdaTail ::= FormalParameterlist PushRParen'->' LambdaBody


Of course this barely scratches at the surface of what complex restructuring would have to be applied to the Expressions sub-grammar.

I guess I'm riding a dead horse here, but want to check with you if someone sees value in further investigation, now or later.
(In reply to comment #86)

> FOR THE CASE even that small overhead should be avoided, I'm fancying a plan C
> that would avoid any look-ahead. But I don't want to dive into this if it has
> been considered already. 

No I didn't try experimenting with something similar to what you outline.
Ayush was also asking about something very similar co-incidentally.

> Of course this barely scratches at the surface of what complex restructuring
> would have to be applied to the Expressions sub-grammar.

:)

> I guess I'm riding a dead horse here, but want to check with you if someone
> sees value in further investigation, now or later.

I think there is value in experimentation - for one thing, as the bottom
passage in comment#15 calls out, I may have taken the unorthodox route
rather readily to establish quickly that we can retain out parser 
infrastructure as is. At the moment though I am quite happy with what we
have. But we can always explore more standard solutions.

I would say - later though. There are bigger challenges waiting in the
inference land we are told :-(
(In reply to comment #86)

> FOR THE CASE even that small overhead should be avoided, I'm fancying a plan C
> that would avoid any look-ahead. But I don't want to dive into this if it has
> been considered already. I'm thinking of this:

I think you are talking of more ambitious scheme than this: but comment#1 point 
(4) is the root idea behind the VanguardParser - with some differences. Instead
saving state, resetting goal and restoring state, we now simply launch another
parser/scanner pair. But the new parser is a bare automaton i.e it is not
actually building an AST.

Now if VanguardParser were really to be a subtype of Parser and we are at
the beginning of '(' Lambdaparameters ')', then the parser would would 
automatically build the parse tree for LambdaExpression which can then 
be plugged into the main parse tree - After all, LR parser builds the tree
bottom up and various smaller trees get integrated into the larger tree
by the very definition of the process. This would ensure that the cost
of looking ahead is 0 since we would have leverage work done in the look
ahead and there is no need to backtrack and rescan as we do now.

The scheme you outline is more challenging in that even in the non
lambda case, the quantum of work done could somehow be beneficial.
(In reply to comment #82)
> (In reply to comment #79)
> 
> > Yeah I caught this as well, but I think the grammar should allow this (looking
> > at the proposed changes in JLS). Only during the semantic analysis phase should
> > we reject it. We can record this in bug 382701
> 
> Why wouldn't this happen automatically ?
By automatically you mean at the time of parsing itself? I thought this is almost the same as 
MethodReference:
 Primary '::' NonWildTypeArgumentsopt Identifier

So while syntactically ok, the surrounding context disallows a nested method reference (I also interpreted this JLS section like comment 85)
I ran out of mean things to try to break the code - no real success in breaking, so it's time to repeat - this time in a definite voice:

(In reply to comment #5)
> Congratulations! So we have hope that we can keep our parser, right? :)

Yes, let's keep this exact version!

I believe all open issues (most being small, non blocking) are being tracked in follow-up bugs.

IF (we get bored some day
   AND we see performance issues with the current implementation
   AND we want to rise to further challenges)
THEN we may investigate what I outlined in comment 86.

Hats off to Srikanth!
(In reply to comment #90)
> I ran out of mean things to try to break the code - no real success in
> breaking, so it's time to repeat - this time in a definite voice:
> 
> (In reply to comment #5)
> > Congratulations! So we have hope that we can keep our parser, right? :)
> 
> Yes, let's keep this exact version!

[...]

> Hats off to Srikanth!

Thank you !

Daniel M & Daniel H - FYI - The question of whether JDT parser can be
enhanced successfully to handle JSR335 parsing complexitities is definitely
decisively answered in the affirmative now that code review (Thanks Stephan !)
and black box  testing/verification (Thanks Ayush!, Thanks Satyam!) are 
complete. 

Hurrah !

Action now shifts to a different theater: see bug 382701.
(In reply to comment #85)
> The way I read the spec the 'inner' reference X::foo cannot be type checked
> because no expected type can be inferred from the context.

You are right and I was wrong in comment# 84. Let us track this via bug 382702.
> Daniel M & Daniel H - FYI - The question of whether JDT parser can be
> enhanced successfully to handle JSR335 parsing complexitities is definitely
> decisively answered in the affirmative now that code review (Thanks Stephan !)
> and black box  testing/verification (Thanks Ayush!, Thanks Satyam!) are 
> complete. 

Great news - thanks to everyone involved in this milestone!
+1. Stephan deeply reviewed all the changes.
(In reply to comment #50)
> Here's one thing that looks wrong to me:
> 
> The consumeReferenceExpression* group of methods uses
> getUnspecifiedReferenceOptimized() to get a SingleNameReference representing
> the Identifier.
> 
> By analogy to FieldReference and MessageSend I'd expect that the Identifier
> is handled by directly fetching the char[] from the identifierStack and
> storing it as-is (no wrapping with a SingleNameReference).
> 
> The reason I believe this will be relevant is how AssistParser & Co. hook
> into the process by overriding getUnspecifiedReferenceOptimized(). I don't
> have a test that shows that this is a problem, but wanted to ask for
> rationale behind the current implementation, first.

Stephan, the last passage - isn't it actually establishing the very case for
why we must use getUnspecifiedReferenceOptimized() and not the other way
about ? I did move to directly fetching the identifier and wonder if that
is the reason why bug 400904 is there. I'll revert to getUnspecifiedReferenceOptimized and see what happens.
(In reply to comment #95)
> (In reply to comment #50)
> > Here's one thing that looks wrong to me:
> > 
> > The consumeReferenceExpression* group of methods uses
> > getUnspecifiedReferenceOptimized() to get a SingleNameReference representing
> > the Identifier.
> > 
> > By analogy to FieldReference and MessageSend I'd expect that the Identifier
> > is handled by directly fetching the char[] from the identifierStack and
> > storing it as-is (no wrapping with a SingleNameReference).
> > 
> > The reason I believe this will be relevant is how AssistParser & Co. hook
> > into the process by overriding getUnspecifiedReferenceOptimized(). I don't
> > have a test that shows that this is a problem, but wanted to ask for
> > rationale behind the current implementation, first.

For the record, this concern is finally addressed in  https://bugs.eclipse.org/bugs/show_bug.cgi?id=402609
